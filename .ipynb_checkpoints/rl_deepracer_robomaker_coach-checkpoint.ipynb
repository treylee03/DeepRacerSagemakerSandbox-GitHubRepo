{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hands-on Exercise 3: Distributed RL training with Amazon SageMaker and AWS RoboMaker for the AWS DeepRacer\n",
    "\n",
    "---\n",
    "## Overview\n",
    "\n",
    "Okay, so now your environment is set up with the AWS CloudFormation template and you have initialized the notebook. For the rest of this exercise, you'll get hands-on experience with Amazon SageMaker and AWS RoboMaker so that you can better understand how they power the AWS DeepRacer.\n",
    "\n",
    "Unlike the first two exercises in this course that had you building, training, and evaluating your models via the console UI, this exercise encourages you to get under the hood of [AWS DeepRacer](https://console.aws.amazon.com/deepracer/home#welcome). You'll go through the build, train, and evaluate process by interacting directly with Amazon SageMaker and AWS RoboMaker. In doing so, you will gain more control over the model training, tuning, and simulation process.\n",
    "\n",
    "![Training in Action](./deepracer-hard-track-world.jpg)\n",
    "\n",
    "---\n",
    "## How it works  \n",
    "\n",
    "![How training works](./training.png)\n",
    "\n",
    "The RL agent (that is, your autonomous car) learns to drive by interacting with its environment (the track) and by taking actions in a given state to maximize the expected rewards. During training, the agent learns what optimal actions are by trial and error, through repeated episodes.  \n",
    "\n",
    "The figure above shows a distributed RL training across Amazon SageMaker and two AWS RoboMaker simulation environments. This distributed RL training performs the **rollouts**, which execute a fixed number of episodes using the current model or policy. The rollouts collect agent experiences (state-transition tuples) and share this data with Amazon SageMaker for training. Amazon SageMaker then updates the model policy, which is used to execute the next sequence of rollouts. This training loop continues until the model converges--that is, until the car learns to drive and stops going off the track. More formally, you can define the problem in terms of the following:  \n",
    "\n",
    "1. **Objective**: Learn to drive autonomously by staying close to the center of the track\n",
    "2. **Environment**: A 3D driving simulator hosted on AWS RoboMaker\n",
    "3. **State**: The driving point of view (POV) image captured by the car's head camera, as shown above\n",
    "4. **Action**: Six discrete steering wheel positions at different angles (configurable)\n",
    "5. **Reward**: Positive reward for staying close to the center line; high penalty for going off-track. This is configurable and can be made more complex (for example, by adding a steering penalty)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the development environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, you will import the Python libraries you need, and set up the environment with a few prerequisites for permissions and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "import sys\n",
    "import urllib.request\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "from IPython.display import Markdown\n",
    "from time import gmtime, strftime\n",
    "sys.path.append(\"common\")\n",
    "from misc import get_execution_role, wait_for_s3_object\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "from markdown_helper import *\n",
    "from botocore.exceptions import UnknownServiceError\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use Boto to call to different services in your AWS account. Running the code block below will set this up and collect the credentials that are currently being passed to your Amazon SageMaker instance to sign any calls you have to make later in this notebook. When this notebook was written, the services used in this exercise (Amazon SageMaker, AWS RoboMaker) have not been deployed to all AWS Regions. A check will be made to ensure that the AWS CloudFormation template to build the base of this exercise has been run inside a supported region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_session = sagemaker.session.Session()\n",
    "aws_region = sage_session.boto_region_name\n",
    "robomaker = boto3.client(\"robomaker\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "role = sagemaker.get_execution_role()\n",
    "roleSplit = role.split(':')\n",
    "accountID = roleSplit[4]\n",
    "\n",
    "if aws_region not in [\"us-east-1\"]:\n",
    "    raise Exception(\"This Notebook needs to be running in AWS Region US-East-1 (N. Virginia). Deploy your AWS cloudformation stack in that region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a new model or retraining an existing one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this notebook will create a new model from scratch. However, you do have the ability to retrain a model you've used before (you might want to consider the model you used in earlier course exercises). To do this, you need to set the bool `retrain` flag below to `0` for a new model or `1` for retraining an old model.\n",
    "\n",
    "If you are retraining an old model, you will have to provide the checkpoint files that were used during the original training. These files can be found in the AWS DeepRacer S3 bucket created by your AWS CloudFormation stack. They follow the naming format `deepracer-trainingexercise` followed by the AWS Region you used and your 12-digit account number.\n",
    "\n",
    "You will find these data files, indexes, and metadata files in the `model` folder in the corresponding jobs prefix. If your model was originally trained via this notebook on 03/21/19-20:03, for instance, you would find those files at directory `/rl-deepracer-sagemaker-19-03-21--20-03/model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoints and other metadata will be stored at: s3://deepracer-trainingexercise-us-east-1-576690301298/rl-deepracersagemaker-19-06-25--09-31\n",
      "RoboMaker logging will be stored at : s3://deepracer-trainingexercise-us-east-1-576690301298/rl-deepracerrobomaker-19-06-25--09-31\n"
     ]
    }
   ],
   "source": [
    "retrain = bool(0)\n",
    "\n",
    "# Define timestamp once, to ensure unique name, but have consistent job names to tie jobs together\n",
    "timestamp = strftime(\"%y-%m-%d--%H-%M\", gmtime())\n",
    "job_name_prefix = 'rl-deepracer'\n",
    "# TODO apend hyphen to prefex\n",
    "# job_name_prefix = 'rl-deepracer-'\n",
    "pretrainModelDesc = \"Default-\"\n",
    "\n",
    "# Duration of job in seconds (2 hours)\n",
    "job_duration_in_seconds = 3600 * 2\n",
    "\n",
    "if retrain == False: # Training a new model \n",
    "    # S3 bucket\n",
    "    s3_bucket = 'deepracer-trainingexercise-' + aws_region + '-' + accountID \n",
    "    s3_prefix = job_name = job_name_prefix + \"sagemaker-\" + timestamp\n",
    "    s3_prefix_robomaker = job_name_prefix + \"robomaker-\" + timestamp\n",
    "    \n",
    "    pretrained_s3_bucket = None\n",
    "    pretrained_s3_prefix = None\n",
    "\n",
    "if retrain == True: # Retraining an old model \n",
    "    \n",
    "    pretrained_s3_bucket = 'deepracer-trainingexercise-' + aws_region + '-' + accountID\n",
    "    pretrained_s3_prefix = 'retrainmodel/' # Don't need to include the 'model/' folder in the prefix\n",
    "    \n",
    "    job_name = job_name_prefix +'-'+ pretrainModelDesc + \"retrain-\" + timestamp\n",
    "    s3_bucket = 'deepracer-trainingexercise-' + aws_region + '-' + accountID\n",
    "    s3_prefix = job_name_prefix +'-'+ pretrainModelDesc + \"sagemaker-retrain-\" + timestamp\n",
    "    s3_prefix_robomaker = job_name_prefix +'-'+ pretrainModelDesc + \"robomaker-retrain-\" + timestamp\n",
    "    \n",
    "s3_output_path = 's3://{}/'.format(s3_bucket) # SDK appends the job name and output folder\n",
    "\n",
    "print('Model checkpoints and other metadata will be stored at: ' + s3_output_path + job_name)\n",
    "print(\"RoboMaker logging will be stored at : {}{}\".format(s3_output_path, s3_prefix_robomaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the VPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Amazon SageMaker and AWS RoboMaker have to communicate with each other over the network, they both need to run in VPC mode. The AWS CloudFormation template you launched built the networking layer that supports these services. However, this notebook needs to discover what VPC ID it is running in and the subnet where AWS Robomaker and Amazon SageMaker can create instances. To support these node-to-node communications, a security group will need to be attached. \n",
    "\n",
    "Running the code block below allows this notebook to discover these resource IDs and load them into memory.\n",
    "\n",
    "This notebook is programmed to look for a VPC with a IP block range of 10.96.0.0/16. If you changed the default AWS CloudFormation stack parameters at stack creation, this code block may fail to run. Make sure the IP block range matches the IP block range of 10.96.0.0/16. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using VPC: vpc-07c48fed79cdeb9b8\n",
      "Using security group: ['sg-0ac42b58e5380e6c3']\n",
      "Using subnets: ['subnet-06b6c4ee99f473cc4', 'subnet-076543dbc741fae50', 'subnet-0e5ad60a5e086d4b7', 'subnet-0dcba498d58079685']\n"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.client('ec2')\n",
    "\n",
    "default_vpc = [vpc['VpcId'] for vpc in ec2.describe_vpcs()['Vpcs'] if vpc[\"CidrBlock\"] == '10.96.0.0/16'][0] \n",
    "\n",
    "default_security_groups = [group[\"GroupId\"] for group in ec2.describe_security_groups()['SecurityGroups'] \\\n",
    "                   if group[\"GroupName\"] == \"default\" and group[\"VpcId\"] == default_vpc]\n",
    "\n",
    "default_subnets = [subnet[\"SubnetId\"] for subnet in ec2.describe_subnets()[\"Subnets\"] \\\n",
    "                  if subnet[\"VpcId\"] == default_vpc and subnet['MapPublicIpOnLaunch']==False]\n",
    "\n",
    "print(\"Using VPC:\", default_vpc)\n",
    "print(\"Using security group:\", default_security_groups)\n",
    "print(\"Using subnets:\", default_subnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the configurations  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running these simulations via Amazon SageMaker, you gain greater control over the settings in the simulated environment and the data being collected. Let's discuss some of these files and the role they play in helping with model learning by rewarding good driving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The reward function\n",
    "\n",
    "The environment is defined in a Python file called “deepracer_env.py,” which can be found at `src/robomaker/environments/`. This file implements the gym interface for your Gazebo-based AWS RoboMaker simulator. This is a common environment file used by both Amazon SageMaker and AWS RoboMaker. The environment variable - `NODE_TYPE` defines which node the code is running on. So the expressions that have `rospy` dependencies are executed on AWS RoboMaker only.  \n",
    "\n",
    "You can experiment with different reward functions by modifying `reward_function` in this file. You can also change the action space and steering angles by modifying the step method in `DeepRacerDiscreteEnv` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# only needed for fake driver setup\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\n",
      "\u001b[37m# gym\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mgym\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mgym\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m spaces\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmath\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Type of worker\u001b[39;49;00m\n",
      "SIMULATION_WORKER = \u001b[33m\"\u001b[39;49;00m\u001b[33mSIMULATION_WORKER\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "SAGEMAKER_TRAINING_WORKER = \u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_TRAINING_WORKER\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "node_type = os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mNODE_TYPE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SIMULATION_WORKER)\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m node_type == SIMULATION_WORKER:\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrospy\u001b[39;49;00m\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mackermann_msgs.msg\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AckermannDriveStamped\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mgazebo_msgs.msg\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ModelState\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mgazebo_msgs.srv\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SetModelState\n",
      "\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msensor_msgs.msg\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image \u001b[34mas\u001b[39;49;00m sensor_image\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdeepracer_msgs.msg\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Progress\n",
      "\n",
      "TRAINING_IMAGE_SIZE = (\u001b[34m160\u001b[39;49;00m, \u001b[34m120\u001b[39;49;00m)\n",
      "FINISH_LINE = \u001b[34m100\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# REWARD ENUM\u001b[39;49;00m\n",
      "CRASHED = \u001b[34m0\u001b[39;49;00m\n",
      "NO_PROGRESS = -\u001b[34m1\u001b[39;49;00m\n",
      "FINISHED = \u001b[34m10000000.0\u001b[39;49;00m\n",
      "MAX_STEPS = \u001b[34m1000000\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# WORLD NAME\u001b[39;49;00m\n",
      "EASY_TRACK_WORLD = \u001b[33m'\u001b[39;49;00m\u001b[33measy_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "MEDIUM_TRACK_WORLD = \u001b[33m'\u001b[39;49;00m\u001b[33mmedium_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "HARD_TRACK_WORLD = \u001b[33m'\u001b[39;49;00m\u001b[33mhard_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# SLEEP INTERVALS\u001b[39;49;00m\n",
      "SLEEP_AFTER_RESET_TIME_IN_SECOND = \u001b[34m0.5\u001b[39;49;00m\n",
      "SLEEP_BETWEEN_ACTION_AND_REWARD_CALCULATION_TIME_IN_SECOND = \u001b[34m0.1\u001b[39;49;00m\n",
      "SLEEP_WAITING_FOR_IMAGE_TIME_IN_SECOND = \u001b[34m0.01\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m### Gym Env ###\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mDeepRacerEnv\u001b[39;49;00m(gym.Env):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "\n",
      "        screen_height = TRAINING_IMAGE_SIZE[\u001b[34m1\u001b[39;49;00m]\n",
      "        screen_width = TRAINING_IMAGE_SIZE[\u001b[34m0\u001b[39;49;00m]\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.on_track = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.progress = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.yaw = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.x = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.y = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.z = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.distance_from_center = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.distance_from_border_1 = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.distance_from_border_2 = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.steps = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.episodes = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.progress_at_beginning_of_race = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.prev_closest_waypoint_index = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.closest_waypoint_index = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# actions -> steering angle, throttle\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.action_space = spaces.Box(low=np.array([-\u001b[34m1\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m]), high=np.array([+\u001b[34m1\u001b[39;49;00m, +\u001b[34m1\u001b[39;49;00m]), dtype=np.float32)\n",
      "\n",
      "        \u001b[37m# given image from simulator\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.observation_space = spaces.Box(low=\u001b[34m0\u001b[39;49;00m, high=\u001b[34m255\u001b[39;49;00m,\n",
      "                                            shape=(screen_height, screen_width, \u001b[34m3\u001b[39;49;00m), dtype=np.uint8)\n",
      "\n",
      "        \u001b[34mif\u001b[39;49;00m node_type == SIMULATION_WORKER:\n",
      "            \u001b[37m# ROS initialization\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.ack_publisher = rospy.Publisher(\u001b[33m'\u001b[39;49;00m\u001b[33m/vesc/low_level/ackermann_cmd_mux/output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                                 AckermannDriveStamped, queue_size=\u001b[34m100\u001b[39;49;00m)\n",
      "            \u001b[36mself\u001b[39;49;00m.racecar_service = rospy.ServiceProxy(\u001b[33m'\u001b[39;49;00m\u001b[33m/gazebo/set_model_state\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, SetModelState)\n",
      "            rospy.init_node(\u001b[33m'\u001b[39;49;00m\u001b[33mrl_coach\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, anonymous=\u001b[36mTrue\u001b[39;49;00m)\n",
      "\n",
      "            \u001b[37m# Subscribe to ROS topics and register callbacks\u001b[39;49;00m\n",
      "            rospy.Subscriber(\u001b[33m'\u001b[39;49;00m\u001b[33m/progress\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, Progress, \u001b[36mself\u001b[39;49;00m.callback_progress)\n",
      "            rospy.Subscriber(\u001b[33m'\u001b[39;49;00m\u001b[33m/camera/zed/rgb/image_rect_color\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, sensor_image, \u001b[36mself\u001b[39;49;00m.callback_image)\n",
      "            \u001b[36mself\u001b[39;49;00m.world_name = rospy.get_param(\u001b[33m'\u001b[39;49;00m\u001b[33mWORLD_NAME\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "            \u001b[36mself\u001b[39;49;00m.set_waypoints()\n",
      "            \u001b[36mself\u001b[39;49;00m.track_length = \u001b[36mself\u001b[39;49;00m.calculate_track_length()\n",
      "            \n",
      "            \u001b[36mself\u001b[39;49;00m.aws_region = rospy.get_param(\u001b[33m'\u001b[39;49;00m\u001b[33mROS_AWS_REGION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.reward_in_episode = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.prev_progress = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mreset\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[34mif\u001b[39;49;00m node_type == SAGEMAKER_TRAINING_WORKER:\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.observation_space.sample()\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mTotal Reward Reward=\u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % \u001b[36mself\u001b[39;49;00m.reward_in_episode,\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mTotal Steps=\u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % \u001b[36mself\u001b[39;49;00m.steps)\n",
      "        \u001b[36mself\u001b[39;49;00m.send_reward_to_cloudwatch(\u001b[36mself\u001b[39;49;00m.reward_in_episode)\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.reward_in_episode = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.reward = \u001b[36mNone\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.done = \u001b[36mFalse\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.next_state = \u001b[36mNone\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.image = \u001b[36mNone\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.steps = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.episodes += \u001b[34m1\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.prev_progress = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.total_progress = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.action_taken = \u001b[34m2\u001b[39;49;00m \u001b[37m#straight\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.prev_action = \u001b[34m2\u001b[39;49;00m \u001b[37m#straight\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.prev_closest_waypoint_index = \u001b[34m0\u001b[39;49;00m \u001b[37m#always starts from first waypoint\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.closest_waypoint_index = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# Reset car in Gazebo\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.send_action(\u001b[34m0\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m)  \u001b[37m# set the throttle to 0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.racecar_reset()\n",
      "        \u001b[36mself\u001b[39;49;00m.steering_angle = \u001b[34m0.0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.throttle = \u001b[34m0.0\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.action_taken = \u001b[34m2.0\u001b[39;49;00m\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.infer_reward_state(\u001b[34m0\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m)\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.next_state\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mracecar_reset\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        rospy.wait_for_service(\u001b[33m'\u001b[39;49;00m\u001b[33mgazebo/set_model_state\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "        modelState = ModelState()\n",
      "        modelState.pose.position.z = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.pose.orientation.x = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.pose.orientation.y = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.pose.orientation.z = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.pose.orientation.w = \u001b[34m0\u001b[39;49;00m  \u001b[37m# Use this to randomize the orientation of the car\u001b[39;49;00m\n",
      "        modelState.twist.linear.x = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.twist.linear.y = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.twist.linear.z = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.twist.angular.x = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.twist.angular.y = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.twist.angular.z = \u001b[34m0\u001b[39;49;00m\n",
      "        modelState.model_name = \u001b[33m'\u001b[39;49;00m\u001b[33mracecar\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.world_name.startswith(MEDIUM_TRACK_WORLD):\n",
      "            modelState.pose.position.x = -\u001b[34m1.40\u001b[39;49;00m\n",
      "            modelState.pose.position.y = \u001b[34m2.13\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.world_name.startswith(EASY_TRACK_WORLD):\n",
      "            modelState.pose.position.x = -\u001b[34m1.44\u001b[39;49;00m\n",
      "            modelState.pose.position.y = -\u001b[34m0.06\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.world_name.startswith(HARD_TRACK_WORLD):\n",
      "            modelState.pose.position.x = \u001b[34m1.75\u001b[39;49;00m\n",
      "            modelState.pose.position.y = \u001b[34m0.6\u001b[39;49;00m\n",
      "            \n",
      "            \u001b[34mdef\u001b[39;49;00m \u001b[32mtoQuaternion\u001b[39;49;00m(pitch, roll, yaw):\n",
      "                cy = np.cos(yaw * \u001b[34m0.5\u001b[39;49;00m)\n",
      "                sy = np.sin(yaw * \u001b[34m0.5\u001b[39;49;00m)\n",
      "                cr = np.cos(roll * \u001b[34m0.5\u001b[39;49;00m)\n",
      "                sr = np.sin(roll * \u001b[34m0.5\u001b[39;49;00m)\n",
      "                cp = np.cos(pitch * \u001b[34m0.5\u001b[39;49;00m)\n",
      "                sp = np.sin(pitch * \u001b[34m0.5\u001b[39;49;00m)\n",
      "\n",
      "                w = cy * cr * cp + sy * sr * sp\n",
      "                x = cy * sr * cp - sy * cr * sp\n",
      "                y = cy * cr * sp + sy * sr * cp\n",
      "                z = sy * cr * cp - cy * sr * sp\n",
      "                \u001b[34mreturn\u001b[39;49;00m [x, y, z, w]\n",
      "\n",
      "            \u001b[37m#clockwise\u001b[39;49;00m\n",
      "            quaternion = toQuaternion(roll=\u001b[34m0.0\u001b[39;49;00m, pitch=\u001b[34m0.0\u001b[39;49;00m, yaw=np.pi)\n",
      "            \u001b[37m#anti-clockwise\u001b[39;49;00m\n",
      "            quaternion = toQuaternion(roll=\u001b[34m0.0\u001b[39;49;00m, pitch=\u001b[34m0.0\u001b[39;49;00m, yaw=\u001b[34m0.0\u001b[39;49;00m)\n",
      "            modelState.pose.orientation.x = quaternion[\u001b[34m0\u001b[39;49;00m]\n",
      "            modelState.pose.orientation.y = quaternion[\u001b[34m1\u001b[39;49;00m]\n",
      "            modelState.pose.orientation.z = quaternion[\u001b[34m2\u001b[39;49;00m]\n",
      "            modelState.pose.orientation.w = quaternion[\u001b[34m3\u001b[39;49;00m]\n",
      "            \n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mUnknown simulation world: {}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[36mself\u001b[39;49;00m.world_name))\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.racecar_service(modelState)\n",
      "        time.sleep(SLEEP_AFTER_RESET_TIME_IN_SECOND)\n",
      "        \u001b[36mself\u001b[39;49;00m.progress_at_beginning_of_race = \u001b[36mself\u001b[39;49;00m.progress\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mstep\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, action):\n",
      "        \u001b[34mif\u001b[39;49;00m node_type == SAGEMAKER_TRAINING_WORKER:\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.observation_space.sample(), \u001b[34m0\u001b[39;49;00m, \u001b[36mFalse\u001b[39;49;00m, {}\n",
      "\n",
      "        \u001b[37m# initialize rewards, next_state, done\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.reward = \u001b[36mNone\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.done = \u001b[36mFalse\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.next_state = \u001b[36mNone\u001b[39;49;00m\n",
      "\n",
      "        steering_angle = \u001b[36mfloat\u001b[39;49;00m(action[\u001b[34m0\u001b[39;49;00m])\n",
      "        throttle = \u001b[36mfloat\u001b[39;49;00m(action[\u001b[34m1\u001b[39;49;00m])\n",
      "        \u001b[36mself\u001b[39;49;00m.steps += \u001b[34m1\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.send_action(steering_angle, throttle)\n",
      "        time.sleep(SLEEP_BETWEEN_ACTION_AND_REWARD_CALCULATION_TIME_IN_SECOND)\n",
      "        \u001b[36mself\u001b[39;49;00m.infer_reward_state(steering_angle, throttle)\n",
      "\n",
      "        info = {}  \u001b[37m# additional data, not to be used for training\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.next_state, \u001b[36mself\u001b[39;49;00m.reward, \u001b[36mself\u001b[39;49;00m.done, info\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcallback_image\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, data):\n",
      "        \u001b[36mself\u001b[39;49;00m.image = data\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcallback_progress\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, data):\n",
      "        \u001b[36mself\u001b[39;49;00m.on_track = \u001b[35mnot\u001b[39;49;00m (data.off_track)\n",
      "        \u001b[36mself\u001b[39;49;00m.progress = data.progress\n",
      "        \u001b[36mself\u001b[39;49;00m.yaw = data.yaw\n",
      "        \u001b[36mself\u001b[39;49;00m.x = data.x\n",
      "        \u001b[36mself\u001b[39;49;00m.y = data.y\n",
      "        \u001b[36mself\u001b[39;49;00m.z = data.z\n",
      "        \u001b[36mself\u001b[39;49;00m.distance_from_center = data.distance_from_center\n",
      "        \u001b[36mself\u001b[39;49;00m.distance_from_border_1 = data.distance_from_border_1\n",
      "        \u001b[36mself\u001b[39;49;00m.distance_from_border_2 = data.distance_from_border_2\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msend_action\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, steering_angle, throttle):\n",
      "        ack_msg = AckermannDriveStamped()\n",
      "        ack_msg.header.stamp = rospy.Time.now()\n",
      "        ack_msg.drive.steering_angle = steering_angle\n",
      "        ack_msg.drive.speed = throttle\n",
      "        \u001b[36mself\u001b[39;49;00m.ack_publisher.publish(ack_msg)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mreward_function\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, on_track, x, y, distance_from_center, car_orientation, progress, steps,\n",
      "                        throttle, steering, track_width, waypoints, closest_waypoints):\n",
      "        \u001b[34mif\u001b[39;49;00m distance_from_center >= \u001b[34m0.0\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m distance_from_center <= \u001b[34m0.02\u001b[39;49;00m:\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[34m1.0\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m distance_from_center >= \u001b[34m0.02\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m distance_from_center <= \u001b[34m0.03\u001b[39;49;00m:\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[34m0.3\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m distance_from_center >= \u001b[34m0.03\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m distance_from_center <= \u001b[34m0.05\u001b[39;49;00m:\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[34m0.1\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34m1e-3\u001b[39;49;00m  \u001b[37m# like crashed\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32minfer_reward_state\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, steering_angle, throttle):\n",
      "        \u001b[37m# Wait till we have a image from the camera\u001b[39;49;00m\n",
      "        \u001b[34mwhile\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.image:\n",
      "            time.sleep(SLEEP_WAITING_FOR_IMAGE_TIME_IN_SECOND)\n",
      "\n",
      "        \u001b[37m# Car environment spits out BGR images by default. Converting to the\u001b[39;49;00m\n",
      "        \u001b[37m# image to RGB.\u001b[39;49;00m\n",
      "        image = Image.frombytes(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, (\u001b[36mself\u001b[39;49;00m.image.width, \u001b[36mself\u001b[39;49;00m.image.height),\n",
      "                                \u001b[36mself\u001b[39;49;00m.image.data, \u001b[33m'\u001b[39;49;00m\u001b[33mraw\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m)\n",
      "        \u001b[37m# resize image ans perform anti-aliasing\u001b[39;49;00m\n",
      "        image = image.resize(TRAINING_IMAGE_SIZE, resample=\u001b[34m2\u001b[39;49;00m).convert(\u001b[33m\"\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        state = np.array(image)\n",
      "\n",
      "       \n",
      "        total_progress = \u001b[36mself\u001b[39;49;00m.progress - \u001b[36mself\u001b[39;49;00m.progress_at_beginning_of_race\n",
      "        \u001b[36mself\u001b[39;49;00m.prev_progress = total_progress\n",
      "        \n",
      "        \u001b[37m# calculate the closest way point \u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.closest_waypoint_index = \u001b[36mself\u001b[39;49;00m.get_closest_waypoint()\n",
      "        \u001b[37m# calculate the current progress with respect to the way points\u001b[39;49;00m\n",
      "        current_progress = \u001b[36mself\u001b[39;49;00m.calculate_current_progress(\u001b[36mself\u001b[39;49;00m.closest_waypoint_index, \u001b[36mself\u001b[39;49;00m.prev_closest_waypoint_index)\n",
      "        \u001b[36mself\u001b[39;49;00m.total_progress = current_progress + \u001b[36mself\u001b[39;49;00m.prev_progress\n",
      "        \u001b[37m# re-assign the prev progress and way point variables\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.prev_progress = \u001b[36mself\u001b[39;49;00m.total_progress\n",
      "        \u001b[36mself\u001b[39;49;00m.prev_closest_waypoint_index = \u001b[36mself\u001b[39;49;00m.closest_waypoint_index\n",
      "\n",
      "        done = \u001b[36mFalse\u001b[39;49;00m\n",
      "        on_track = \u001b[36mself\u001b[39;49;00m.on_track\n",
      "        \u001b[34mif\u001b[39;49;00m on_track != \u001b[34m1\u001b[39;49;00m:\n",
      "            reward = CRASHED\n",
      "            done = \u001b[36mTrue\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m total_progress >= FINISH_LINE:  \u001b[37m# reached max waypoints\u001b[39;49;00m\n",
      "            \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCongratulations! You finished the race!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.steps == \u001b[34m0\u001b[39;49;00m:\n",
      "                reward = \u001b[34m0.0\u001b[39;49;00m\n",
      "                done = \u001b[36mFalse\u001b[39;49;00m\n",
      "            \u001b[34melse\u001b[39;49;00m:\n",
      "                reward = FINISHED / \u001b[36mself\u001b[39;49;00m.steps\n",
      "                done = \u001b[36mTrue\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            reward = \u001b[36mself\u001b[39;49;00m.reward_function(on_track, \u001b[36mself\u001b[39;49;00m.x, \u001b[36mself\u001b[39;49;00m.y, \u001b[36mself\u001b[39;49;00m.distance_from_center, \u001b[36mself\u001b[39;49;00m.yaw,\n",
      "                                          \u001b[36mself\u001b[39;49;00m.total_progress, \u001b[36mself\u001b[39;49;00m.steps, throttle, steering_angle, \u001b[36mself\u001b[39;49;00m.road_width,\n",
      "                                          \u001b[36mlist\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.waypoints), \u001b[36mself\u001b[39;49;00m.get_closest_waypoint())\n",
      "            \n",
      "            reward += \u001b[34m0.5\u001b[39;49;00m \u001b[37m#reward bonus for surviving\u001b[39;49;00m\n",
      "            \n",
      "            \u001b[37m#smooth\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.action_taken == \u001b[36mself\u001b[39;49;00m.prev_action:\n",
      "                reward += \u001b[34m0.5\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.prev_action = \u001b[36mself\u001b[39;49;00m.action_taken\n",
      "\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mStep No=\u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % \u001b[36mself\u001b[39;49;00m.steps,\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mStep Reward=\u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % reward)\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.reward_in_episode += reward\n",
      "        \u001b[36mself\u001b[39;49;00m.reward = reward\n",
      "        \u001b[36mself\u001b[39;49;00m.done = done\n",
      "        \u001b[36mself\u001b[39;49;00m.next_state = state\n",
      "        \n",
      "        \u001b[37m# Trace logs to help us debug and visualize the training runs\u001b[39;49;00m\n",
      "        stdout_ = \u001b[33m'\u001b[39;49;00m\u001b[33mSIM_TRACE_LOG:\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.4f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.4f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.4f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.4f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.4f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.4f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % (\n",
      "        \u001b[36mself\u001b[39;49;00m.episodes, \u001b[36mself\u001b[39;49;00m.steps, \u001b[36mself\u001b[39;49;00m.x, \u001b[36mself\u001b[39;49;00m.y,\n",
      "        \u001b[36mself\u001b[39;49;00m.yaw,\n",
      "        \u001b[36mself\u001b[39;49;00m.steering_angle,\n",
      "        \u001b[36mself\u001b[39;49;00m.throttle,\n",
      "        \u001b[36mself\u001b[39;49;00m.action_taken,\n",
      "        \u001b[36mself\u001b[39;49;00m.reward,\n",
      "        \u001b[36mself\u001b[39;49;00m.total_progress,\n",
      "        \u001b[34m0\u001b[39;49;00m, \u001b[37m#self.get_waypoint_action(), #the expert action at the next waypoint\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.done,\n",
      "        \u001b[36mself\u001b[39;49;00m.on_track,\n",
      "        current_progress,\n",
      "        \u001b[34m0\u001b[39;49;00m, \u001b[37m#self.initidxWayPoint, #starting waypoint for an episode\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.closest_waypoint_index,\n",
      "        \u001b[36mself\u001b[39;49;00m.track_length,\n",
      "        time.time())\n",
      "        \u001b[34mprint\u001b[39;49;00m(stdout_)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32msend_reward_to_cloudwatch\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, reward):\n",
      "        session = boto3.session.Session()\n",
      "        cloudwatch_client = session.client(\u001b[33m'\u001b[39;49;00m\u001b[33mcloudwatch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, region_name=\u001b[36mself\u001b[39;49;00m.aws_region)\n",
      "        cloudwatch_client.put_metric_data(\n",
      "            MetricData=[\n",
      "                {\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mMetricName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mDeepRacerRewardPerEpisode\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mUnit\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mNone\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mValue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: reward\n",
      "                },\n",
      "            ],\n",
      "            Namespace=\u001b[33m'\u001b[39;49;00m\u001b[33mAWSRoboMakerSimulation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "        )\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mset_waypoints\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.world_name.startswith(MEDIUM_TRACK_WORLD):\n",
      "            \u001b[36mself\u001b[39;49;00m.waypoints = vertices = np.zeros((\u001b[34m8\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m))\n",
      "            \u001b[36mself\u001b[39;49;00m.road_width = \u001b[34m0.50\u001b[39;49;00m\n",
      "            vertices[\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = -\u001b[34m0.99\u001b[39;49;00m; vertices[\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m2.25\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m1\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m0.69\u001b[39;49;00m;  vertices[\u001b[34m1\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m2.26\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m2\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m1.37\u001b[39;49;00m;  vertices[\u001b[34m2\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.67\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m3\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m1.48\u001b[39;49;00m;  vertices[\u001b[34m3\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = -\u001b[34m1.54\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m4\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m0.81\u001b[39;49;00m;  vertices[\u001b[34m4\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = -\u001b[34m2.44\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m5\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = -\u001b[34m1.25\u001b[39;49;00m; vertices[\u001b[34m5\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = -\u001b[34m2.30\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m6\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = -\u001b[34m1.67\u001b[39;49;00m; vertices[\u001b[34m6\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = -\u001b[34m1.64\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m7\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = -\u001b[34m1.73\u001b[39;49;00m; vertices[\u001b[34m7\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.63\u001b[39;49;00m;\n",
      "        \u001b[34melif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.world_name.startswith(EASY_TRACK_WORLD):\n",
      "            \u001b[36mself\u001b[39;49;00m.waypoints = vertices = np.zeros((\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m))\n",
      "            \u001b[36mself\u001b[39;49;00m.road_width = \u001b[34m0.90\u001b[39;49;00m\n",
      "            vertices[\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = -\u001b[34m1.08\u001b[39;49;00m;   vertices[\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = -\u001b[34m0.05\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m1\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] =  \u001b[34m1.08\u001b[39;49;00m;   vertices[\u001b[34m1\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = -\u001b[34m0.05\u001b[39;49;00m;\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            \u001b[36mself\u001b[39;49;00m.waypoints = vertices = np.zeros((\u001b[34m30\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m))\n",
      "            \u001b[36mself\u001b[39;49;00m.road_width = \u001b[34m0.44\u001b[39;49;00m\n",
      "            vertices[\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m1.5\u001b[39;49;00m;     vertices[\u001b[34m0\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m0.58\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m1\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m5.5\u001b[39;49;00m;     vertices[\u001b[34m1\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m0.58\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m2\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m5.6\u001b[39;49;00m;     vertices[\u001b[34m2\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m0.6\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m3\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m5.7\u001b[39;49;00m;     vertices[\u001b[34m3\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m0.65\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m4\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m5.8\u001b[39;49;00m;     vertices[\u001b[34m4\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m0.7\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m5\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m5.9\u001b[39;49;00m;     vertices[\u001b[34m5\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m0.8\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m6\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m6.0\u001b[39;49;00m;     vertices[\u001b[34m6\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m0.9\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m7\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m6.08\u001b[39;49;00m;    vertices[\u001b[34m7\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.1\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m8\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m6.1\u001b[39;49;00m;     vertices[\u001b[34m8\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.2\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m9\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m6.1\u001b[39;49;00m;     vertices[\u001b[34m9\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.3\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m10\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m6.1\u001b[39;49;00m;    vertices[\u001b[34m10\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.4\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m11\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m6.07\u001b[39;49;00m;   vertices[\u001b[34m11\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.5\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m12\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m6.05\u001b[39;49;00m;   vertices[\u001b[34m12\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.6\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m13\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m6\u001b[39;49;00m;      vertices[\u001b[34m13\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.7\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m14\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m5.9\u001b[39;49;00m;    vertices[\u001b[34m14\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.8\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m15\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m5.75\u001b[39;49;00m;   vertices[\u001b[34m15\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1.9\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m16\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m5.6\u001b[39;49;00m;    vertices[\u001b[34m16\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m2.0\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m17\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m4.2\u001b[39;49;00m;    vertices[\u001b[34m17\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m2.02\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m18\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m4\u001b[39;49;00m;      vertices[\u001b[34m18\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m2.1\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m19\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m2.6\u001b[39;49;00m;    vertices[\u001b[34m19\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m3.92\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m20\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m2.4\u001b[39;49;00m;    vertices[\u001b[34m20\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m4\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m21\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m1.2\u001b[39;49;00m;    vertices[\u001b[34m21\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m3.95\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m22\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m1.1\u001b[39;49;00m;    vertices[\u001b[34m22\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m3.92\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m23\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m1\u001b[39;49;00m;      vertices[\u001b[34m23\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m3.88\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m24\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m0.8\u001b[39;49;00m;    vertices[\u001b[34m24\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m3.72\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m25\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m0.6\u001b[39;49;00m;    vertices[\u001b[34m25\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m3.4\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m26\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m0.58\u001b[39;49;00m;   vertices[\u001b[34m26\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m3.3\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m27\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m0.57\u001b[39;49;00m;   vertices[\u001b[34m27\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m3.2\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m28\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m1\u001b[39;49;00m;      vertices[\u001b[34m28\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m1\u001b[39;49;00m;\n",
      "            vertices[\u001b[34m29\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m] = \u001b[34m1.25\u001b[39;49;00m;   vertices[\u001b[34m29\u001b[39;49;00m][\u001b[34m1\u001b[39;49;00m] = \u001b[34m0.7\u001b[39;49;00m;\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mget_closest_waypoint\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        res = \u001b[34m0\u001b[39;49;00m\n",
      "        index = \u001b[34m0\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.x\n",
      "        y = \u001b[36mself\u001b[39;49;00m.y\n",
      "        minDistance = \u001b[36mfloat\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33minf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        \u001b[34mfor\u001b[39;49;00m row \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.waypoints:\n",
      "            distance = math.sqrt((row[\u001b[34m0\u001b[39;49;00m] - x) * (row[\u001b[34m0\u001b[39;49;00m] - x) + (row[\u001b[34m1\u001b[39;49;00m] - y) * (row[\u001b[34m1\u001b[39;49;00m] - y))\n",
      "            \u001b[34mif\u001b[39;49;00m distance < minDistance:\n",
      "                minDistance = distance\n",
      "                res = index\n",
      "            index = index + \u001b[34m1\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m res\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcalculate_current_progress\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, closest_waypoint_index, prev_closest_waypoint_index):\n",
      "        current_progress = \u001b[34m0.0\u001b[39;49;00m\n",
      "        \n",
      "        \u001b[37m# calculate distance in meters\u001b[39;49;00m\n",
      "        coor1 = \u001b[36mself\u001b[39;49;00m.waypoints[closest_waypoint_index]\n",
      "        coor2 = \u001b[36mself\u001b[39;49;00m.waypoints[prev_closest_waypoint_index]\n",
      "        current_progress = math.sqrt((coor1[\u001b[34m0\u001b[39;49;00m] - coor2[\u001b[34m0\u001b[39;49;00m]) *(coor1[\u001b[34m0\u001b[39;49;00m] - coor2[\u001b[34m0\u001b[39;49;00m]) + (coor1[\u001b[34m1\u001b[39;49;00m] - coor2[\u001b[34m1\u001b[39;49;00m]) * (coor1[\u001b[34m1\u001b[39;49;00m] - coor2[\u001b[34m1\u001b[39;49;00m]))\n",
      "        \n",
      "        \u001b[37m# convert to ratio and then percentage\u001b[39;49;00m\n",
      "        current_progress /= \u001b[36mself\u001b[39;49;00m.track_length\n",
      "        current_progress *= \u001b[34m100.0\u001b[39;49;00m\n",
      "        \n",
      "        \u001b[34mreturn\u001b[39;49;00m current_progress\n",
      "    \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcalculate_track_length\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        track_length = \u001b[34m0.0\u001b[39;49;00m\n",
      "        prev_row = \u001b[36mself\u001b[39;49;00m.waypoints[\u001b[34m0\u001b[39;49;00m]\n",
      "        \u001b[34mfor\u001b[39;49;00m row \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.waypoints[\u001b[34m1\u001b[39;49;00m:]:\n",
      "            track_length += math.sqrt((row[\u001b[34m0\u001b[39;49;00m] - prev_row[\u001b[34m0\u001b[39;49;00m]) * (row[\u001b[34m0\u001b[39;49;00m] - prev_row[\u001b[34m0\u001b[39;49;00m]) + (row[\u001b[34m1\u001b[39;49;00m] - prev_row[\u001b[34m1\u001b[39;49;00m]) * (row[\u001b[34m1\u001b[39;49;00m] - prev_row[\u001b[34m1\u001b[39;49;00m]))\n",
      "            prev_row = row\n",
      "            \n",
      "        \u001b[34mif\u001b[39;49;00m track_length == \u001b[34m0.0\u001b[39;49;00m:\n",
      "            \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mERROR: Track length is zero.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "            \u001b[34mraise\u001b[39;49;00m\n",
      "            \n",
      "        \u001b[34mreturn\u001b[39;49;00m track_length\n",
      "    \n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mDeepRacerDiscreteEnv\u001b[39;49;00m(DeepRacerEnv):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "        DeepRacerEnv.\u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.action_space = spaces.Discrete(\u001b[34m6\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mstep\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, action):\n",
      "\n",
      "        \u001b[37m# Convert discrete to continuous\u001b[39;49;00m\n",
      "        throttle = \u001b[34m1.0\u001b[39;49;00m\n",
      "        throttle_multiplier = \u001b[34m0.8\u001b[39;49;00m\n",
      "        throttle = throttle*throttle_multiplier\n",
      "        steering_angle = \u001b[34m0.8\u001b[39;49;00m\n",
      "        \n",
      "        \u001b[36mself\u001b[39;49;00m.throttle, \u001b[36mself\u001b[39;49;00m.steering_angle = \u001b[36mself\u001b[39;49;00m.default_6_actions(throttle, steering_angle, action)\n",
      "        \n",
      "        \u001b[36mself\u001b[39;49;00m.action_taken = action\n",
      "        \n",
      "        continous_action = [\u001b[36mself\u001b[39;49;00m.steering_angle, \u001b[36mself\u001b[39;49;00m.throttle]\n",
      "\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36msuper\u001b[39;49;00m().step(continous_action)\n",
      "    \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mdefault_6_actions\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, throttle, steering_angle, action):\n",
      "        \u001b[34mif\u001b[39;49;00m action == \u001b[34m0\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0.8\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m1\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m0.8\u001b[39;49;00m \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m2\u001b[39;49;00m:  \u001b[37m# straight\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m3\u001b[39;49;00m:  \u001b[37m# move slight left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0.2\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m4\u001b[39;49;00m:  \u001b[37m# move slight right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m0.2\u001b[39;49;00m \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m5\u001b[39;49;00m:  \u001b[37m# slow straight\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0\u001b[39;49;00m  \n",
      "            throttle = throttle/\u001b[34m2\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:  \u001b[37m# should not be here\u001b[39;49;00m\n",
      "            \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid action\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            \n",
      "        \u001b[34mreturn\u001b[39;49;00m throttle, steering_angle\n",
      "    \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtwo_steering_one_throttle_5_states\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,throttle_, steering_angle_, action):\n",
      "        \u001b[34mif\u001b[39;49;00m action == \u001b[34m0\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m1\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_            \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m2\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m3\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m4\u001b[39;49;00m:  \u001b[37m# straight\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0\u001b[39;49;00m\n",
      "            throttle = throttle_\n",
      "     \n",
      "        \u001b[34melse\u001b[39;49;00m:  \u001b[37m# should not be here\u001b[39;49;00m\n",
      "            \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid action\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            \n",
      "        \u001b[34mreturn\u001b[39;49;00m throttle, steering_angle\n",
      "            \n",
      "    \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtwo_steering_two_throttle_10_states\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,throttle_, steering_angle_, action):\n",
      "        \u001b[34mif\u001b[39;49;00m action == \u001b[34m0\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m1\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_            \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m2\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m3\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m4\u001b[39;49;00m:  \u001b[37m# straight\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0\u001b[39;49;00m\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m5\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_ * \u001b[34m0.5\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m6\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_ * \u001b[34m0.5\u001b[39;49;00m           \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m7\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_ * \u001b[34m0.5\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m8\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_ * \u001b[34m0.5\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m9\u001b[39;49;00m:  \u001b[37m# straight\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0\u001b[39;49;00m\n",
      "            throttle = throttle_ * \u001b[34m0.5\u001b[39;49;00m\n",
      " \n",
      "        \u001b[34melse\u001b[39;49;00m:  \u001b[37m# should not be here\u001b[39;49;00m\n",
      "            \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid action\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            \n",
      "        \u001b[34mreturn\u001b[39;49;00m throttle, steering_angle\n",
      "    \n",
      "    \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtwo_steering_three_throttle_15_states\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,throttle_, steering_angle_, action):\n",
      "        \n",
      "        \u001b[37m# Convert discrete to continuous\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m action == \u001b[34m0\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m1\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_            \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m2\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m3\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m4\u001b[39;49;00m:  \u001b[37m# straight\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0\u001b[39;49;00m\n",
      "            throttle = throttle_\n",
      "            \n",
      "            \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m5\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = steering_angle_\n",
      "            throttle = \u001b[34m0.5\u001b[39;49;00m * throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m6\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = \u001b[34m0.5\u001b[39;49;00m * throttle_      \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m7\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = \u001b[34m0.5\u001b[39;49;00m * throttle_\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m8\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = \u001b[34m0.5\u001b[39;49;00m * throttle_          \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m9\u001b[39;49;00m:  \u001b[37m# slow straight\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0\u001b[39;49;00m\n",
      "            throttle = throttle_ *\u001b[34m0.5\u001b[39;49;00m\n",
      "            \n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m10\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_ * \u001b[34m2.0\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m11\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m1\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_ * \u001b[34m2.0\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m12\u001b[39;49;00m:  \u001b[37m# move left\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_ * \u001b[34m2.0\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m13\u001b[39;49;00m:  \u001b[37m# move right\u001b[39;49;00m\n",
      "            steering_angle = -\u001b[34m0.5\u001b[39;49;00m * steering_angle_\n",
      "            throttle = throttle_ * \u001b[34m2.0\u001b[39;49;00m\n",
      "        \u001b[34melif\u001b[39;49;00m action == \u001b[34m14\u001b[39;49;00m:  \u001b[37m# fast straight\u001b[39;49;00m\n",
      "            steering_angle = \u001b[34m0\u001b[39;49;00m\n",
      "            throttle = throttle_ * \u001b[34m2.0\u001b[39;49;00m\n",
      "            \n",
      "        \u001b[34melse\u001b[39;49;00m:  \u001b[37m# should not be here\u001b[39;49;00m\n",
      "            \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mInvalid action\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            \n",
      "        \u001b[34mreturn\u001b[39;49;00m throttle, steering_angle\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/robomaker/environments/deepracer_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "One way to improve your model's performance is to enact a better or more effective training process. For example, to develop a robust model, training must provide your agent more or less evenly distributed sampling over the agent's action space. This requires a sufficient mix of explorations and exploitations. The variables that affect this include the amount of training data used (number of episodes between each training and batch size), how fast the agent can learn (learning rate), and the portion of exploration (entropy). To make training practical, you may want to experiment with speeding up the learning process. The variables that affect this include learning rate, batch size, number of epochs, and discount factor.\n",
    "\n",
    "The variables affecting the training process are known as *hyperparameters*. They're algorithm attributes that are not properties of the underlying model. Unfortunately, hyperparameters are empirical in nature. Their optimal values are not known *a priori* for all practical purposes and require systematic experimentation through iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.agents.clipped_ppo_agent\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ClippedPPOAgentParameters\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.base_parameters\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m VisualizationParameters, PresetValidationParameters\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.core_types\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TrainingSteps, EnvironmentEpisodes, EnvironmentSteps, RunPhase\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.environments.gym_environment\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m GymVectorEnvironment\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.graph_managers.basic_rl_graph_manager\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BasicRLGraphManager\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.graph_managers.graph_manager\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ScheduleParameters\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.schedules\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LinearSchedule\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.exploration_policies.categorical\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CategoricalParameters\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.filters.filter\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m NoInputFilter, NoOutputFilter, InputFilter\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.filters.observation.observation_stacking_filter\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ObservationStackingFilter\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.filters.observation.observation_rgb_to_y_filter\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ObservationRGBToYFilter\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.filters.observation.observation_to_uint8_filter\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ObservationToUInt8Filter\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.memories.memory\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MemoryGranularity\n",
      "\n",
      "\u001b[37m####################\u001b[39;49;00m\n",
      "\u001b[37m# Graph Scheduling #\u001b[39;49;00m\n",
      "\u001b[37m####################\u001b[39;49;00m\n",
      "\n",
      "schedule_params = ScheduleParameters()\n",
      "schedule_params.improve_steps = TrainingSteps(\u001b[34m10000000\u001b[39;49;00m)\n",
      "schedule_params.steps_between_evaluation_periods = EnvironmentEpisodes(\u001b[34m40\u001b[39;49;00m)\n",
      "schedule_params.evaluation_steps = EnvironmentEpisodes(\u001b[34m5\u001b[39;49;00m)\n",
      "schedule_params.heatup_steps = EnvironmentSteps(\u001b[34m0\u001b[39;49;00m)\n",
      "\n",
      "\u001b[37m#########\u001b[39;49;00m\n",
      "\u001b[37m# Agent #\u001b[39;49;00m\n",
      "\u001b[37m#########\u001b[39;49;00m\n",
      "agent_params = ClippedPPOAgentParameters()\n",
      "\n",
      "agent_params.memory.max_size = (MemoryGranularity.Transitions, \u001b[34m10\u001b[39;49;00m**\u001b[34m5\u001b[39;49;00m)\n",
      "\n",
      "agent_params.network_wrappers[\u001b[33m'\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].learning_rate = \u001b[34m0.0003\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m'\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].input_embedders_parameters[\u001b[33m'\u001b[39;49;00m\u001b[33mobservation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].activation_function = \u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m'\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].middleware_parameters.activation_function = \u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m'\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].batch_size = \u001b[34m64\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m'\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].optimizer_epsilon = \u001b[34m1e-5\u001b[39;49;00m\n",
      "agent_params.network_wrappers[\u001b[33m'\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].adam_optimizer_beta2 = \u001b[34m0.999\u001b[39;49;00m\n",
      "\n",
      "agent_params.algorithm.clip_likelihood_ratio_using_epsilon = \u001b[34m0.2\u001b[39;49;00m\n",
      "agent_params.algorithm.clipping_decay_schedule = LinearSchedule(\u001b[34m1.0\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m, \u001b[34m1000000\u001b[39;49;00m)\n",
      "agent_params.algorithm.beta_entropy = \u001b[34m0.01\u001b[39;49;00m  \u001b[37m# also try 0.001\u001b[39;49;00m\n",
      "agent_params.algorithm.gae_lambda = \u001b[34m0.95\u001b[39;49;00m\n",
      "agent_params.algorithm.discount = \u001b[34m0.999\u001b[39;49;00m\n",
      "agent_params.algorithm.optimization_epochs = \u001b[34m10\u001b[39;49;00m\n",
      "agent_params.algorithm.estimate_state_value_using_gae = \u001b[36mTrue\u001b[39;49;00m\n",
      "agent_params.algorithm.num_steps_between_copying_online_weights_to_target = EnvironmentEpisodes(\u001b[34m20\u001b[39;49;00m)\n",
      "agent_params.algorithm.num_consecutive_playing_steps = EnvironmentEpisodes(\u001b[34m20\u001b[39;49;00m)\n",
      "agent_params.exploration = CategoricalParameters()\n",
      "\n",
      "\u001b[37m###############\u001b[39;49;00m\n",
      "\u001b[37m# Environment #\u001b[39;49;00m\n",
      "\u001b[37m###############\u001b[39;49;00m\n",
      "DeepRacerInputFilter = InputFilter(is_a_reference_filter=\u001b[36mTrue\u001b[39;49;00m)\n",
      "DeepRacerInputFilter.add_observation_filter(\u001b[33m'\u001b[39;49;00m\u001b[33mobservation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mto_grayscale\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, ObservationRGBToYFilter())\n",
      "DeepRacerInputFilter.add_observation_filter(\u001b[33m'\u001b[39;49;00m\u001b[33mobservation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mto_uint8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, ObservationToUInt8Filter(\u001b[34m0\u001b[39;49;00m, \u001b[34m255\u001b[39;49;00m))\n",
      "DeepRacerInputFilter.add_observation_filter(\u001b[33m'\u001b[39;49;00m\u001b[33mobservation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mstacking\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, ObservationStackingFilter(\u001b[34m1\u001b[39;49;00m))\n",
      "\n",
      "env_params = GymVectorEnvironment()\n",
      "env_params.default_input_filter = DeepRacerInputFilter\n",
      "env_params.level = \u001b[33m'\u001b[39;49;00m\u001b[33mSageMaker-DeepRacer-Discrete-v0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\n",
      "vis_params = VisualizationParameters()\n",
      "vis_params.dump_mp4 = \u001b[36mFalse\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m########\u001b[39;49;00m\n",
      "\u001b[37m# Test #\u001b[39;49;00m\n",
      "\u001b[37m########\u001b[39;49;00m\n",
      "preset_validation_params = PresetValidationParameters()\n",
      "preset_validation_params.test = \u001b[36mTrue\u001b[39;49;00m\n",
      "preset_validation_params.min_reward_threshold = \u001b[34m20\u001b[39;49;00m\n",
      "preset_validation_params.max_episodes_to_achieve_reward = \u001b[34m1000\u001b[39;49;00m\n",
      "\n",
      "graph_manager = BasicRLGraphManager(agent_params=agent_params, env_params=env_params,\n",
      "                                    schedule_params=schedule_params, vis_params=vis_params,\n",
      "                                    preset_validation_params=preset_validation_params)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/robomaker/presets/deepracer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training entry point\n",
    "\n",
    "The training code is written in the file `training_worker.py`, which is uploaded in the `/src` directory. This is the code that is being used to start a Redis server that will receive agent experiences by rollout training worker[s]. After receiving these agent experiences, `training_worker.py` will trigger model training after a defined number of episodes are received. After the training cycle has finished, it will upload the new model weights to the defined S3 bucket, and notify the workers to update their models and execute the next set of episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmarkov.s3_client\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SageS3Client\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmarkov.utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m get_ip_from_host, DoorMan\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmarkov.s3_boto_data_store\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m S3BotoDataStore, S3BotoDataStoreParameters\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m core_types\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.base_parameters\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TaskParameters, DistributedCoachSynchronizationType, Frameworks\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.logger\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m screen\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.memories.backend.redis\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RedisPubSubMemoryBackendParameters\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mrl_coach.utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m short_dynamic_import\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
      "\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "\n",
      "PRETRAINED_MODEL_DIR = \u001b[33m\"\u001b[39;49;00m\u001b[33m./pretrained_checkpoint\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "INTERMEDIATE_FOLDER = \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/output/intermediate/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtraining_worker\u001b[39;49;00m(graph_manager, checkpoint_dir, use_pretrained_model, framework):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    restore a checkpoint then perform rollouts using the restored model\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \u001b[37m# initialize graph\u001b[39;49;00m\n",
      "    task_parameters = TaskParameters()\n",
      "    task_parameters.\u001b[31m__dict__\u001b[39;49;00m[\u001b[33m'\u001b[39;49;00m\u001b[33mcheckpoint_save_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = checkpoint_dir\n",
      "    task_parameters.\u001b[31m__dict__\u001b[39;49;00m[\u001b[33m'\u001b[39;49;00m\u001b[33mcheckpoint_save_secs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = \u001b[34m20\u001b[39;49;00m\n",
      "    task_parameters.\u001b[31m__dict__\u001b[39;49;00m[\u001b[33m'\u001b[39;49;00m\u001b[33mexperiment_path\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = INTERMEDIATE_FOLDER\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m framework.lower() == \u001b[33m\"\u001b[39;49;00m\u001b[33mmxnet\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "        task_parameters.framework_type = Frameworks.mxnet\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mhasattr\u001b[39;49;00m(graph_manager, \u001b[33m'\u001b[39;49;00m\u001b[33magent_params\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "            \u001b[34mfor\u001b[39;49;00m network_parameters \u001b[35min\u001b[39;49;00m graph_manager.agent_params.network_wrappers.values():\n",
      "                network_parameters.framework = Frameworks.mxnet\n",
      "        \u001b[34melif\u001b[39;49;00m \u001b[36mhasattr\u001b[39;49;00m(graph_manager, \u001b[33m'\u001b[39;49;00m\u001b[33magents_params\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "            \u001b[34mfor\u001b[39;49;00m ap \u001b[35min\u001b[39;49;00m graph_manager.agents_params:\n",
      "                \u001b[34mfor\u001b[39;49;00m network_parameters \u001b[35min\u001b[39;49;00m ap.network_wrappers.values():\n",
      "                    network_parameters.framework = Frameworks.mxnet\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m use_pretrained_model:\n",
      "        task_parameters.\u001b[31m__dict__\u001b[39;49;00m[\u001b[33m'\u001b[39;49;00m\u001b[33mcheckpoint_restore_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = PRETRAINED_MODEL_DIR\n",
      "\n",
      "    graph_manager.create_graph(task_parameters)\n",
      "\n",
      "    \u001b[37m# save randomly initialized graph\u001b[39;49;00m\n",
      "    graph_manager.save_checkpoint()\n",
      "\n",
      "    \u001b[37m# training loop\u001b[39;49;00m\n",
      "    steps = \u001b[34m0\u001b[39;49;00m\n",
      "    graph_manager.setup_memory_backend()\n",
      "\n",
      "    \u001b[37m# To handle SIGTERM\u001b[39;49;00m\n",
      "    door_man = DoorMan()\n",
      "\n",
      "    \u001b[34mtry\u001b[39;49;00m:\n",
      "        \u001b[34mwhile\u001b[39;49;00m (steps < graph_manager.improve_steps.num_steps):\n",
      "            graph_manager.phase = core_types.RunPhase.TRAIN\n",
      "            graph_manager.fetch_from_worker(graph_manager.agent_params.algorithm.num_consecutive_playing_steps)\n",
      "            graph_manager.phase = core_types.RunPhase.UNDEFINED\n",
      "\n",
      "            \u001b[34mif\u001b[39;49;00m graph_manager.should_train():\n",
      "                steps += graph_manager.agent_params.algorithm.num_consecutive_playing_steps.num_steps\n",
      "\n",
      "                graph_manager.phase = core_types.RunPhase.TRAIN\n",
      "                graph_manager.train()\n",
      "                graph_manager.phase = core_types.RunPhase.UNDEFINED\n",
      "\n",
      "                \u001b[34mif\u001b[39;49;00m graph_manager.agent_params.algorithm.distributed_coach_synchronization_type == DistributedCoachSynchronizationType.SYNC:\n",
      "                    graph_manager.save_checkpoint()\n",
      "                \u001b[34melse\u001b[39;49;00m:\n",
      "                    graph_manager.occasionally_save_checkpoint()\n",
      "\n",
      "            \u001b[34mif\u001b[39;49;00m door_man.terminate_now:\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mReceived SIGTERM. Checkpointing before exiting.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "                graph_manager.save_checkpoint()\n",
      "                \u001b[34mbreak\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mAn error occured while training: \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % e)\n",
      "    \u001b[34mfinally\u001b[39;49;00m:\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mTerminating training worker\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        graph_manager.data_store.upload_finished_file()\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "    screen.set_use_colors(\u001b[36mFalse\u001b[39;49;00m)\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m-c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m--checkpoint-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) Path to a local folder containing a checkpoint to write the model to.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=\u001b[33m'\u001b[39;49;00m\u001b[33m./checkpoint\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--pretrained-checkpoint-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) Path to a local folder for downloading a pre-trained model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=PRETRAINED_MODEL_DIR)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--s3_bucket\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) S3 bucket\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_SHARED_S3_BUCKET_PATH\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mgsaur-test\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--s3_prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) S3 prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--framework\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) tensorflow or mxnet\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=\u001b[33m'\u001b[39;49;00m\u001b[33mtensorflow\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--pretrained_s3_bucket\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) S3 bucket for pre-trained model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--pretrained_s3_prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) S3 prefix for pre-trained model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--RLCOACH_PRESET\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) Default preset to use\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        default=\u001b[33m'\u001b[39;49;00m\u001b[33mdeepracer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--aws_region\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33m(string) AWS region\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\n",
      "                        required=\u001b[36mTrue\u001b[39;49;00m)\n",
      "\n",
      "    args, unknown = parser.parse_known_args()\n",
      "\n",
      "    s3_client = SageS3Client(bucket=args.s3_bucket, s3_prefix=args.s3_prefix, aws_region=args.aws_region)\n",
      "\n",
      "    \u001b[37m# Import to register the environment with Gym\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrobomaker.environments\u001b[39;49;00m\n",
      "\n",
      "    preset_location = \u001b[33m\"\u001b[39;49;00m\u001b[33mrobomaker.presets.\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m:graph_manager\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % args.RLCOACH_PRESET\n",
      "    graph_manager = short_dynamic_import(preset_location, ignore_module_case=\u001b[36mTrue\u001b[39;49;00m)\n",
      "\n",
      "    host_ip_address = get_ip_from_host()\n",
      "    s3_client.write_ip_config(host_ip_address)\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mUploaded IP address information to S3: \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % host_ip_address)\n",
      "\n",
      "    use_pretrained_model = \u001b[36mFalse\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m args.pretrained_s3_bucket \u001b[35mand\u001b[39;49;00m args.pretrained_s3_prefix:\n",
      "        s3_client_pretrained = SageS3Client(bucket=args.pretrained_s3_bucket,\n",
      "                                            s3_prefix=args.pretrained_s3_prefix,\n",
      "                                            aws_region=args.aws_region)\n",
      "        s3_client_pretrained.download_model(PRETRAINED_MODEL_DIR)\n",
      "        use_pretrained_model = \u001b[36mTrue\u001b[39;49;00m\n",
      "\n",
      "    memory_backend_params = RedisPubSubMemoryBackendParameters(redis_address=\u001b[33m\"\u001b[39;49;00m\u001b[33mlocalhost\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "                                                               redis_port=\u001b[34m6379\u001b[39;49;00m,\n",
      "                                                               run_type=\u001b[33m'\u001b[39;49;00m\u001b[33mtrainer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                                               channel=args.s3_prefix)\n",
      "\n",
      "    graph_manager.agent_params.memory.register_var(\u001b[33m'\u001b[39;49;00m\u001b[33mmemory_backend_params\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, memory_backend_params)\n",
      "\n",
      "    ds_params_instance = S3BotoDataStoreParameters(bucket_name=args.s3_bucket,\n",
      "                                                   checkpoint_dir=args.checkpoint_dir,\n",
      "                                                   s3_folder=args.s3_prefix,\n",
      "                                                   aws_region=args.aws_region)\n",
      "    graph_manager.data_store_params = ds_params_instance\n",
      "\n",
      "    data_store = S3BotoDataStore(ds_params_instance)\n",
      "    data_store.graph_manager = graph_manager\n",
      "    graph_manager.data_store = data_store\n",
      "\n",
      "    training_worker(\n",
      "        graph_manager=graph_manager,\n",
      "        checkpoint_dir=args.checkpoint_dir,\n",
      "        use_pretrained_model=use_pretrained_model,\n",
      "        framework=args.framework\n",
      "    )\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mstart_redis_server\u001b[39;49;00m():\n",
      "    p = subprocess.Popen(\u001b[33m\"\u001b[39;49;00m\u001b[33mredis-server --bind 0.0.0.0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, shell=\u001b[36mTrue\u001b[39;49;00m, stderr=subprocess.STDOUT)\n",
      "    time.sleep(\u001b[34m5\u001b[39;49;00m)\n",
      "    \u001b[34mif\u001b[39;49;00m p.poll() \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCould not start Redis server.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mRedis server started successfully!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m p\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mNODE_TYPE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33mSAGEMAKER_TRAINING_WORKER\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    redis = start_redis_server()\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/training_worker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading configurations to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload `src/robomaker/presets/deepracer.py` and `src/robomaker/environments/deepracer_env.py` to `s3_bucket` `s3_prefix`. These files must be present when the Amazon SageMaker training job is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: src/robomaker/environments/deepracer_env.py to s3://deepracer-trainingexercise-us-east-1-576690301298/rl-deepracersagemaker-19-06-25--09-31/environments/deepracer_env.py\n",
      "upload: src/robomaker/environments/__init__.py to s3://deepracer-trainingexercise-us-east-1-576690301298/rl-deepracersagemaker-19-06-25--09-31/environments/__init__.py\n",
      "upload: src/robomaker/presets/__init__.py to s3://deepracer-trainingexercise-us-east-1-576690301298/rl-deepracersagemaker-19-06-25--09-31/presets/__init__.py\n",
      "upload: src/robomaker/presets/deepracer.py to s3://deepracer-trainingexercise-us-east-1-576690301298/rl-deepracersagemaker-19-06-25--09-31/presets/deepracer.py\n"
     ]
    }
   ],
   "source": [
    "s3_location = \"s3://%s/%s\" % (s3_bucket, s3_prefix)\n",
    "\n",
    "# Make any changes to the envrironment and preset files below and upload these files\n",
    "!aws s3 cp src/robomaker/environments/ {s3_location}/environments/ --recursive --exclude \".ipynb_checkpoints*\" --exclude \"*.pyc\"\n",
    "!aws s3 cp src/robomaker/presets/ {s3_location}/presets/ --recursive --exclude \".ipynb_checkpoints*\" --exclude \"*.pyc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLEstimator for training RL jobs\n",
    "\n",
    "To set up your training environment, you will call the class RLEstimator. This estimator executes an RLEstimator script in a managed RL execution environment within an Amazon SageMaker training job. The managed RL environment is an Amazon-built Docker container that executes functions defined in the supplied entry_point Python script.\n",
    "\n",
    "[RLEstimator Doc](https://sagemaker.readthedocs.io/en/stable/sagemaker.rl.html)\n",
    "\n",
    "When calling this class, we can define:\n",
    "1. Source directory, which has the environment file, preset and training code\n",
    "2. Entry point as the training code\n",
    "3. Specify the RL toolkit and framework used. This then will apply to the RL container\n",
    "4. Define the RLCOACH preset of `deepracer` \n",
    "5. Training parameters\n",
    "  - instance count - **Only 1 training instance is supported for now**\n",
    "  - instance type  - Default to ml.c4.2xlarge\n",
    "  - job name \n",
    "  - s3_bucket - Bucket to store training data\n",
    "  - s3_prefix - Prefix to store model checkpoint and metadata \n",
    "  - pretrained_s3_bucket - S3 Bucket where a prior model is saved. Only needed if retraining\n",
    "  - pretrained_s3_prefix - The path to where the file is saved. Only needed if retraining\n",
    "6.  Metrics that you want to capture from Amazon CloudWatch logs to monitor the training process. \n",
    "    \n",
    "Training is not started until you call the fit()\n",
    "    \n",
    "Below are algorithm-specific parameters which might change for different algorithms. In this example, we use [ClippedPPO](https://coach.nervanasys.com/algorithms/policy_optimization/cppo/index.html). This data could be sent to Amazon CloudWatch or Amazon SageMaker Notebooks for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    # Training> Name=main_level/agent, Worker=0, Episode=19, Total reward=-102.88, Steps=19019, Training iteration=1\n",
    "    {'Name': 'reward-training',\n",
    "     'Regex': '^Training>.*Total reward=(.*?),'},\n",
    "    \n",
    "    # Policy training> Surrogate loss=-0.32664725184440613, KL divergence=7.255815035023261e-06, Entropy=2.83156156539917, training epoch=0, learning_rate=0.00025\n",
    "    {'Name': 'ppo-surrogate-loss',\n",
    "     'Regex': '^Policy training>.*Surrogate loss=(.*?),'},\n",
    "     {'Name': 'ppo-entropy',\n",
    "     'Regex': '^Policy training>.*Entropy=(.*?),'},\n",
    "   \n",
    "    # Testing> Name=main_level/agent, Worker=0, Episode=19, Total reward=1359.12, Steps=20015, Training iteration=2\n",
    "    {'Name': 'reward-testing',\n",
    "     'Regex': '^Testing>.*Total reward=(.*?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Logging Bucket: deepracer-trainingexercise-us-east-1-576690301298\n",
      "S3 Logging Prefix: rl-deepracersagemaker-19-06-25--09-31\n",
      "Pretrained Model Bucket: None\n",
      "Pretrained Model Prefix: None\n"
     ]
    }
   ],
   "source": [
    "RLCOACH_PRESET = \"deepracer\"\n",
    "instance_type = \"ml.c4.2xlarge\"\n",
    "\n",
    "print('S3 Logging Bucket: ' + s3_bucket)\n",
    "print('S3 Logging Prefix: ' + s3_prefix)\n",
    "\n",
    "#if retrain == True:\n",
    "print('Pretrained Model Bucket: ' + str(pretrained_s3_bucket))\n",
    "print('Pretrained Model Prefix: ' + str(pretrained_s3_bucket))\n",
    "estimator = RLEstimator(entry_point=\"training_worker.py\",\n",
    "                        source_dir='src',\n",
    "                        dependencies=[\"common/sagemaker_rl\"],\n",
    "                        toolkit=RLToolkit.COACH,\n",
    "                        toolkit_version='0.11',\n",
    "                        framework=RLFramework.TENSORFLOW,\n",
    "                        role=role,\n",
    "                        train_instance_type=instance_type,\n",
    "                        train_instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix,\n",
    "                        train_max_run=job_duration_in_seconds, # Maximum runtime in seconds\n",
    "                        hyperparameters={\"pretrained_s3_bucket\": pretrained_s3_bucket,\n",
    "                                         \"pretrained_s3_prefix\": pretrained_s3_prefix,\n",
    "                                         \"s3_bucket\": s3_bucket,\n",
    "                                         \"s3_prefix\": s3_prefix,\n",
    "                                         \"aws_region\": aws_region, \n",
    "                                         \"RLCOACH_PRESET\": RLCOACH_PRESET,\n",
    "                                      },\n",
    "                        metric_definitions = metric_definitions,\n",
    "                        subnets=default_subnets, # Required for VPC mode\n",
    "                        security_group_ids=default_security_groups, # Required for VPC mode\n",
    "                    )\n",
    "estimator.fit(job_name=job_name, wait=False, logs=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up AWS Robomaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the simulation environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, AWS RoboMaker will need a package containing the simulation environment. Below, you will download a package created by the AWS RoboMaker product team. \n",
    "\n",
    "This file is big, and it is not going to change frequently. So rather than downloading it each time you train a model, just check if that file is there. If you want to update this file, you can simply rename it or delete it from your S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepracer application simulation bundle found at:\n",
      "s3://deepracer-trainingexercise-us-east-1-576690301298/deepracer/simulation_ws.tar.gz\n",
      "Delete or rename this file in s3 to download a new source from deepracer team\n"
     ]
    }
   ],
   "source": [
    "simulation_application_bundle_location = \"https://s3.amazonaws.com/deepracer-managed-resources/deepracer-github-simapp.tar.gz\"\n",
    "\n",
    "\n",
    "bundle_s3_key = 'deepracer/simulation_ws.tar.gz'\n",
    "\n",
    "result = s3.list_objects(Bucket=s3_bucket,Prefix=bundle_s3_key)\n",
    "if 'Contents' not in result:\n",
    "    print('Deepracer application simulation bundle not found... Downloading it now')\n",
    "    !wget {simulation_application_bundle_location}\n",
    "    print('Uploading simulation bundle to S3.')\n",
    "    !aws s3 cp deepracer-github-simapp.tar.gz s3://{s3_bucket}/{bundle_s3_key}\n",
    "else:\n",
    "    print('Deepracer application simulation bundle found at:')\n",
    "    print('s3://'+s3_bucket+'/'+bundle_s3_key)\n",
    "    print('Delete or rename this file in s3 to download a new source from deepracer team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload this to AWS RoboMaker as a simulation application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a new simulation app with ARN: arn:aws:robomaker:us-east-1:576690301298:simulation-application/deepracerSagemakerSimulation-19-06-25--09-31/1561455125677\n"
     ]
    }
   ],
   "source": [
    "app_name = \"deepracerSagemakerSimulation-\" + timestamp\n",
    "\n",
    "bundle_s3_key = 'deepracer/simulation_ws.tar.gz'\n",
    "bundle_source = {'s3Bucket': s3_bucket,\n",
    "                 's3Key': bundle_s3_key,\n",
    "                 'architecture': \"X86_64\"}\n",
    "simulation_software_suite={'name': 'Gazebo',\n",
    "                           'version': '7'}\n",
    "robot_software_suite={'name': 'ROS',\n",
    "                      'version': 'Kinetic'}\n",
    "rendering_engine={'name': 'OGRE', 'version': '1.x'}\n",
    "\n",
    "try:\n",
    "    response = robomaker.create_simulation_application(name=app_name,\n",
    "                                                   sources=[bundle_source],\n",
    "                                                   simulationSoftwareSuite=simulation_software_suite,\n",
    "                                                   robotSoftwareSuite=robot_software_suite,\n",
    "                                                   renderingEngine=rendering_engine\n",
    "                                                  )\n",
    "    simulation_app_arn = response[\"arn\"]\n",
    "    print(\"Created a new simulation app with ARN:\", simulation_app_arn)\n",
    "except Exception as e:\n",
    "    if \"AccessDeniedException\" in str(e):\n",
    "        display(Markdown(generate_help_for_robomaker_all_permissions(role)))\n",
    "        raise e\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the simulation job on AWS RoboMaker\n",
    "\n",
    "Before launching the simulation job on AWS RoboMaker, first make sure that all your defined parameters are correct for your testing scenario. This simulation can take several minutes to load, and it's billed by the hour--so make sure everything is correct before you begin.\n",
    "\n",
    "`World_NAME` is name of the world or track that you will load into AWS RoboMaker. \n",
    "\n",
    "1. `\"easy_track\"` - Drag race, long straight roadway with a center line down the middle \n",
    "2. `\"medium_track\"` - A big O, with four left turns to make a big loop\n",
    "3. `\"hard_track\"` - A more complex track that has two long straightaways, as well as a double left turn and a single right turn\n",
    "\n",
    "TODO be sure to discuss this track option limitation\n",
    "\n",
    "Create [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) simulation jobs to simulate the environment and share this data with Amazon SageMaker for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Environment Variables:\n",
      "Model S3 Bucket: deepracer-trainingexercise-us-east-1-576690301298\n",
      "Model S3 Prefix: rl-deepracersagemaker-19-06-23--23-46\n",
      "AWS Region: us-east-1\n",
      "Track Name: hard_track\n",
      "MARKOV Presets: deepracer.py\n",
      "Number of Worker: 1\n",
      "\n",
      "Simulation Application Files:\n",
      "SimApp ARN: arn:aws:robomaker:us-east-1:576690301298:simulation-application/deepracerSagemakerSimulation-19-06-23--23-46/1561333584868\n",
      "SimApp Package Name: deepracer_simulation\n",
      "SimApp Launch File: distributed_training.launch\n",
      "\n",
      "Networking Settings:\n",
      "Subnet: subnet-06b6c4ee99f473cc4\n",
      "Subnet: subnet-076543dbc741fae50\n",
      "Subnet: subnet-0e5ad60a5e086d4b7\n",
      "Subnet: subnet-0dcba498d58079685\n",
      "Security Groups: sg-0ac42b58e5380e6c3\n",
      "Public IP: True\n",
      "\n",
      "Robomaker Create Simulation Parameters:\n",
      "Robomaker Role ARN: arn:aws:iam::576690301298:role/SageMaker-For-DeepRacer-S-SageMakerNotebookInstanc-BTNU4TWJNWDS\n",
      "Simulation Job Duration (Seconds): 7200\n",
      "Simulation Fail Behavior: Continue\n",
      "Output Bucket: deepracer-trainingexercise-us-east-1-576690301298\n",
      "Output Prefix: rl-deepracerrobomaker-19-06-23--23-46\n"
     ]
    }
   ],
   "source": [
    "# Use more rollout workers for faster convergence\n",
    "num_simulation_workers = 1\n",
    "sim_failure_behavior = \"Continue\"\n",
    "\n",
    "envriron_vars = {\n",
    "                 \"MODEL_S3_BUCKET\": s3_bucket,\n",
    "                 \"MODEL_S3_PREFIX\": s3_prefix,\n",
    "                 \"ROS_AWS_REGION\": aws_region,\n",
    "                 \"WORLD_NAME\": \"hard_track\",  # Can be one of \"easy_track\", \"medium_track\", \"hard_track\"\n",
    "                 \"MARKOV_PRESET_FILE\": \"%s.py\" % RLCOACH_PRESET,\n",
    "                 \"NUMBER_OF_ROLLOUT_WORKERS\": str(num_simulation_workers)}\n",
    "\n",
    "\n",
    "simulation_application = {\"application\": simulation_app_arn,\n",
    "                          \"launchConfig\": {\"packageName\": \"deepracer_simulation\",\n",
    "                                           \"launchFile\": \"distributed_training.launch\",\n",
    "                                           \"environmentVariables\": envriron_vars}\n",
    "                         }\n",
    "                            \n",
    "vpcConfig = {\"subnets\": default_subnets,\n",
    "             \"securityGroups\": default_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "print('Simulation Environment Variables:')\n",
    "print('Model S3 Bucket: '+envriron_vars['MODEL_S3_BUCKET'])\n",
    "print('Model S3 Prefix: '+envriron_vars['MODEL_S3_PREFIX'])\n",
    "print('AWS Region: '+envriron_vars['ROS_AWS_REGION'])\n",
    "print('Track Name: '+envriron_vars['WORLD_NAME'])\n",
    "print('MARKOV Presets: '+envriron_vars['MARKOV_PRESET_FILE'])\n",
    "print('Number of Worker: '+envriron_vars['NUMBER_OF_ROLLOUT_WORKERS'])\n",
    "print()\n",
    "print('Simulation Application Files:')\n",
    "print('SimApp ARN: '+simulation_application['application'])\n",
    "print('SimApp Package Name: '+simulation_application['launchConfig']['packageName'])\n",
    "print('SimApp Launch File: '+simulation_application['launchConfig']['launchFile'])\n",
    "print()\n",
    "print('Networking Settings:')\n",
    "print('Subnet: ' + vpcConfig['subnets'][0])\n",
    "print('Subnet: ' + vpcConfig['subnets'][1])\n",
    "print('Subnet: ' + vpcConfig['subnets'][2])\n",
    "print('Subnet: ' + vpcConfig['subnets'][3])\n",
    "print('Security Groups: '+vpcConfig['securityGroups'][0])\n",
    "print('Public IP: '+str(vpcConfig['assignPublicIp']))\n",
    "print()\n",
    "print('Robomaker Create Simulation Parameters:')\n",
    "print('Robomaker Role ARN: '+role)\n",
    "print('Simulation Job Duration (Seconds): '+str(job_duration_in_seconds))\n",
    "print('Simulation Fail Behavior: '+sim_failure_behavior)\n",
    "print('Output Bucket: '+s3_bucket)\n",
    "print('Output Prefix: '+s3_prefix_robomaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is correct, run the code block below to start the simulator. If everything was done correctly, you should see the simulated track in AWS RoboMaker with your car navigating that track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the following jobs:\n",
      "Job ARN arn:aws:robomaker:us-east-1:576690301298:simulation-job/sim-mnjhtfkcbkmy\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for job_no in range(num_simulation_workers):\n",
    "    response =  robomaker.create_simulation_job(iamRole=role,\n",
    "                                            clientRequestToken=strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "                                            maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                            failureBehavior=sim_failure_behavior,\n",
    "                                            simulationApplications=[simulation_application],\n",
    "                                            vpcConfig=vpcConfig,\n",
    "                                            outputLocation={\"s3Bucket\":s3_bucket, \"s3Prefix\":s3_prefix_robomaker}\n",
    "                                            )\n",
    "    responses.append(response)\n",
    "\n",
    "print(\"Created the following jobs:\")\n",
    "job_arns = [response[\"arn\"] for response in responses]\n",
    "for job_arn in job_arns:\n",
    "    print(\"Job ARN\", job_arn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing simulations in AWS RoboMaker\n",
    "\n",
    "Your simulation will load in 10-15 minutes. After it loads, click the URL below to open the AWS RoboMaker service page for the simulation you just launched. There, you can open Gazebo to see your car running in the simulated environment.  \n",
    "\n",
    "Troubleshooting\n",
    "\n",
    "1. If your reward function is not valid Python syntax or causes an error when you run it, you could end up crashing the simulation. If Gazebo fails to load the simulation, this could be one of the causes.\n",
    "\n",
    "\n",
    "2. If your car is just sitting in the corner (x=0,y=0) and not moving, and you are attempting to retrain an old model, your old model may not have been loaded correctly. Check that the correct model files were uploaded to the right location as defined in 'pretrain_s3_bucket' and 'pretrain_s3_prefix'\n",
    "\n",
    "    The training algorithm has two phases. The first is when the RL model is used to make the car move in the track, while the second is when the algorithm uses the information gathered in the first phase to improve the model. In the second phase, no new commands are sent to the car, meaning it will appear as if it is stopped, spinning in circles, or drifting off aimlessly.\n",
    "\n",
    "\n",
    "3. It is possible to move elements of the simulated track in AWS RoboMaker Gazebo. Doing so will affect how the model is seeing and could adversely affect model training. When navigating around this window, be careful not to move objects, or you may have to restart training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Click on the following links for visualization of simulation jobs on RoboMaker Console\n",
       "- [Simulation 1](https://us-east-1.console.aws.amazon.com/robomaker/home?region=us-east-1#simulationJobs/sim-mnjhtfkcbkmy)  \n",
       "\n",
       "You can click on Gazebo after you open the above link to start the simulator."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(generate_robomaker_links(job_arns, aws_region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics for training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your model is being trained, it will send several metrics to Amazon CloudWatch as both metrics and logs. One of these is the number of rewards that your model earned per episode. This data is appended to a file in your S3 bucket over the course of the training. The first cell builds the plot to display this data, and the second code cell is downloading the latest data set from training and graphing it to help you see if your model is training and how effectively.\n",
    "\n",
    "You can simply re-run the second code block to update this graph over the course of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create local folder /tmp/rl-deepracersagemaker-19-06-23--23-46\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = \"/tmp/{}\".format(job_name)\n",
    "os.system(\"mkdir {}\".format(tmp_dir))\n",
    "print(\"Create local folder {}\".format(tmp_dir))\n",
    "intermediate_folder_key = \"{}/output/intermediate\".format(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for s3://deepracer-trainingexercise-us-east-1-576690301298/rl-deepracersagemaker-19-06-23--23-46/output/intermediate/worker_0.simple_rl_graph.main_level.main_level.agent_0.csv...\n",
      "Downloading rl-deepracersagemaker-19-06-23--23-46/output/intermediate/worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_name = \"worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\"\n",
    "key = intermediate_folder_key + \"/\" + csv_file_name\n",
    "wait_for_s3_object(s3_bucket, key, tmp_dir)\n",
    "\n",
    "csv_file = \"{}/{}\".format(tmp_dir, csv_file_name)\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df.dropna(subset=['Training Reward'])\n",
    "x_axis = 'Episode #'\n",
    "y_axis = 'Training Reward'\n",
    "\n",
    "plt = df.plot(x=x_axis,y=y_axis, figsize=(12,5), legend=True, style='b-')\n",
    "plt.set_ylabel(y_axis);\n",
    "plt.set_xlabel(x_axis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up training resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following two code blocks will clean up the Amazon SageMaker training instance and the AWS RoboMaker simulation job. This should happen automatically if your training finished successfully, but if you want to terminate a training that's still running, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_arn in job_arns:\n",
    "    robomaker.cancel_simulation_job(job=job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the StopTrainingJob operation: The request was rejected because the training job is in status Stopped.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-1b4ed7e55fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msage_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the StopTrainingJob operation: The request was rejected because the training job is in status Stopped."
     ]
    }
   ],
   "source": [
    "sage_session.sagemaker_client.stop_training_job(TrainingJobName=estimator._current_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, a model has been trained and saved to the bucket defined in `s3_bucket` to a path of `s3_prefix`. Inside this folder in Amazon S3, you will find a few directories:\n",
    "\n",
    "1. `environments` - Location of `deepracer_env.py` used in this simulation\n",
    "2. `ip` - Status and IP address from simulator \n",
    "3. `model` - Model checkpoint files (you'll need these when retraining a model you've trained previously) \n",
    "4. `output` - A finished, packaged, and optimized model, which you could load on your AWS DeepRacer car \n",
    "5. `output/intermediate` - The CSV file of number of training rewards over the number of training episodes\n",
    "5. `presets` - Location of `deepracer.py` used in this simulation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation jobs are deployed like training jobs. However, you do not need to deploy an Amazon SageMaker training instance to apply new learning to the working model. The point of an evaluation is to help you assess the model's behaviors in a controlled simulation.\n",
    "\n",
    "Our evaluation is based on the number of successful laps around the track the car makes. `NUMBER_OF_TRIALS` is currently set to `20`, and will be running on `hard_track`. The length of time the car has to complete these `20` laps would be defined by `job_duration_in_seconds`. This value was defined for your training job, but if you'd like to decrease it, you can uncomment it below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the following job:\n",
      "Job ARN arn:aws:robomaker:us-east-1:576690301298:simulation-job/sim-mrmt14fgz9xw\n"
     ]
    }
   ],
   "source": [
    "envriron_vars = {\"MODEL_S3_BUCKET\": s3_bucket,\n",
    "                 \"MODEL_S3_PREFIX\": s3_prefix,\n",
    "                 \"ROS_AWS_REGION\": aws_region,\n",
    "                 \"NUMBER_OF_TRIALS\": str(20),\n",
    "                 \"MARKOV_PRESET_FILE\": \"%s.py\" % RLCOACH_PRESET,\n",
    "                 \"WORLD_NAME\": \"hard_track\",\n",
    "                 }\n",
    "\n",
    "# Duration of evaluation job in seconds (1 hours)\n",
    "# job_duration_in_seconds = 3600 * 1 \n",
    "\n",
    "simulation_application = {\"application\":simulation_app_arn,\n",
    "                          \"launchConfig\": {\"packageName\": \"deepracer_simulation\",\n",
    "                                           \"launchFile\": \"evaluation.launch\",\n",
    "                                           \"environmentVariables\": envriron_vars}\n",
    "                         }\n",
    "                            \n",
    "vpcConfig = {\"subnets\": default_subnets,\n",
    "             \"securityGroups\": default_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "response =  robomaker.create_simulation_job(iamRole=role,\n",
    "                                        clientRequestToken=strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "                                        maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                        failureBehavior=\"Continue\",\n",
    "                                        simulationApplications=[simulation_application],\n",
    "                                        vpcConfig=vpcConfig,\n",
    "                                        outputLocation={\"s3Bucket\":s3_bucket, \"s3Prefix\":s3_prefix_robomaker}\n",
    "                                        )\n",
    "print(\"Created the following job:\")\n",
    "print(\"Job ARN\", response[\"arn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up simulation application resource\n",
    "\n",
    "Your evaluation job may fail if your car cannot complete the defined number of successful trials. This could indicate that you need to do more training.\n",
    "\n",
    "You can point this notebook to the model training checkpoint files, and refine your mode better as you get more familiar with these configurations and how the model performs under different conditions.\n",
    "\n",
    "To clear the outputs of these code blocks, click **Kernel** on the Jupyter file bar and then select **Restart and Clear Output**'. This will reset all the variables defined during this run and clear the outputs, letting you start fresh again.\n",
    "\n",
    "Running the code block below will ensure that the AWS RoboMaker evaluation simulation app has been shut down.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a0cc6adb-9672-11e9-8211-4d4341fd698b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Mon, 24 Jun 2019 11:24:28 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'a0cc6adb-9672-11e9-8211-4d4341fd698b',\n",
       "   'x-amz-apigw-id': 'byDk3Ho4IAMFxlg=',\n",
       "   'x-amzn-trace-id': 'Root=1-5d10b2eb-bd9a32763a9b0472f2b36b4c'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robomaker.delete_simulation_application(application=simulation_app_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to be walking away from this exercise for a while, consider stopping this Amazon SageMaker instance. It's running on an ml.t3.xlarge. The AWS CloudFormation stack can be left, as the networking is part of the AWS free tier. Amazon S3 will bill on a price per GB per month for the data that is saved in `s3_bucket`. When you want to come back to this exercise, simply start this Amazon SageMaker instance and launch this Jupyter notebook again.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Congratulations! You now have successfully:\n",
    "1. Configured the appropriate environment and installed the right packages to utilize Amazon SageMaker\n",
    "2. Used Amazon SageMaker to build, train, and evaluate a reinforcement learning model for AWS DeepRacer\n",
    "3. Created, launched, and visualized a simulated environment in AWS RoboMaker|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Model Artifacts to Team Tracker\n",
    "\n",
    "add all artifacts to csv that can be used to determine the best model at a given time\n",
    "\n",
    "this should be done after training/evaluation (above) and before commit\n",
    "\n",
    "each row will be given unique id that must be used in Git commits and pushes to GitHub repo\n",
    "\n",
    "commit the following files:\n",
    "\n",
    "1. rl_deepracer_robomaker_coach.ipynb\n",
    "2. deepracer_env.py\n",
    "3. deepracer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 11 record(s) to deepracer-tracker.csv\n"
     ]
    }
   ],
   "source": [
    "tracker_s3_bucket = 'deepracer-tracker'\n",
    "tracker_s3_key = 'deepracer-tracker.csv'\n",
    "\n",
    "s3_tracker_url = 's3://{}/{}'.format(tracker_s3_bucket, tracker_s3_key)\n",
    "\n",
    "# Convert CSV as DataFrame\n",
    "df = pd.read_csv(s3_tracker_url, header=0, sep=',')\n",
    "# list(df.columns)\n",
    "\n",
    "# Make alterations to DataFrame\n",
    "id = accountID + '-' + timestamp\n",
    "modDf = df.append(pd.Series([id, s3_output_path], index=df.columns ), ignore_index=True)\n",
    "# modDf.head()\n",
    "\n",
    "# # Write CSV to S3 object\n",
    "def _write_dataframe_to_csv_on_s3(dataframe, filename):\n",
    "    \"\"\" Write a dataframe to a CSV on S3 \"\"\"\n",
    "    print(\"Writing {} record(s) to {}\".format(len(dataframe), filename))\n",
    "    # Create buffer\n",
    "    csv_buffer = StringIO()\n",
    "    # Write dataframe to buffer\n",
    "    dataframe.to_csv(csv_buffer, sep=',', index=False)\n",
    "    # Write buffer to S3 object\n",
    "    s3.put_object(Body=csv_buffer.getvalue(), Bucket=tracker_s3_bucket, Key=tracker_s3_key)\n",
    "\n",
    "_write_dataframe_to_csv_on_s3(modDf, tracker_s3_key)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
