{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hands-on Exercise 3: Distributed RL training with Amazon SageMaker and AWS RoboMaker for the AWS DeepRacer\n",
    "\n",
    "---\n",
    "## Overview\n",
    "\n",
    "Okay, so now your environment is set up with the AWS CloudFormation template and you have initialized the notebook. For the rest of this exercise, you'll get hands-on experience with Amazon SageMaker and AWS RoboMaker so that you can better understand how they power the AWS DeepRacer.\n",
    "\n",
    "Unlike the first two exercises in this course that had you building, training, and evaluating your models via the console UI, this exercise encourages you to get under the hood of [AWS DeepRacer](https://console.aws.amazon.com/deepracer/home#welcome). You'll go through the build, train, and evaluate process by interacting directly with Amazon SageMaker and AWS RoboMaker. In doing so, you will gain more control over the model training, tuning, and simulation process.\n",
    "\n",
    "![Training in Action](./deepracer-hard-track-world.jpg)\n",
    "\n",
    "---\n",
    "## How it works  \n",
    "\n",
    "![How training works](./training.png)\n",
    "\n",
    "The RL agent (that is, your autonomous car) learns to drive by interacting with its environment (the track) and by taking actions in a given state to maximize the expected rewards. During training, the agent learns what optimal actions are by trial and error, through repeated episodes.  \n",
    "\n",
    "The figure above shows a distributed RL training across Amazon SageMaker and two AWS RoboMaker simulation environments. This distributed RL training performs the **rollouts**, which execute a fixed number of episodes using the current model or policy. The rollouts collect agent experiences (state-transition tuples) and share this data with Amazon SageMaker for training. Amazon SageMaker then updates the model policy, which is used to execute the next sequence of rollouts. This training loop continues until the model converges--that is, until the car learns to drive and stops going off the track. More formally, you can define the problem in terms of the following:  \n",
    "\n",
    "1. **Objective**: Learn to drive autonomously by staying close to the center of the track\n",
    "2. **Environment**: A 3D driving simulator hosted on AWS RoboMaker\n",
    "3. **State**: The driving point of view (POV) image captured by the car's head camera, as shown above\n",
    "4. **Action**: Six discrete steering wheel positions at different angles (configurable)\n",
    "5. **Reward**: Positive reward for staying close to the center line; high penalty for going off-track. This is configurable and can be made more complex (for example, by adding a steering penalty)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the development environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, you will import the Python libraries you need, and set up the environment with a few prerequisites for permissions and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "import sys\n",
    "import urllib.request\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "from IPython.display import Markdown\n",
    "from time import gmtime, strftime\n",
    "sys.path.append(\"common\")\n",
    "from misc import get_execution_role, wait_for_s3_object\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "from markdown_helper import *\n",
    "from botocore.exceptions import UnknownServiceError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use Boto to call to different services in your AWS account. Running the code block below will set this up and collect the credentials that are currently being passed to your Amazon SageMaker instance to sign any calls you have to make later in this notebook. When this notebook was written, the services used in this exercise (Amazon SageMaker, AWS RoboMaker) have not been deployed to all AWS Regions. A check will be made to ensure that the AWS CloudFormation template to build the base of this exercise has been run inside a supported region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_session = sagemaker.session.Session()\n",
    "aws_region = sage_session.boto_region_name\n",
    "robomaker = boto3.client(\"robomaker\")\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "role = sagemaker.get_execution_role()\n",
    "roleSplit = role.split(':')\n",
    "accountID = roleSplit[4]\n",
    "\n",
    "if aws_region not in [\"us-east-1\"]:\n",
    "    raise Exception(\"This Notebook needs to be running in AWS Region US-East-1 (N. Virginia). Deploy your AWS cloudformation stack in that region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a new model or retraining an existing one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this notebook will create a new model from scratch. However, you do have the ability to retrain a model you've used before (you might want to consider the model you used in earlier course exercises). To do this, you need to set the bool `retrain` flag below to `0` for a new model or `1` for retraining an old model.\n",
    "\n",
    "If you are retraining an old model, you will have to provide the checkpoint files that were used during the original training. These files can be found in the AWS DeepRacer S3 bucket created by your AWS CloudFormation stack. They follow the naming format `deepracer-trainingexercise` followed by the AWS Region you used and your 12-digit account number.\n",
    "\n",
    "You will find these data files, indexes, and metadata files in the `model` folder in the corresponding jobs prefix. If your model was originally trained via this notebook on 03/21/19-20:03, for instance, you would find those files at directory `/rl-deepracer-sagemaker-19-03-21--20-03/model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = bool(0)\n",
    "\n",
    "# Define timestamp once, to ensure unique name, but have consistent job names to tie jobs together\n",
    "timestamp = strftime(\"%y-%m-%d--%H-%M\", gmtime())\n",
    "job_name_prefix = 'rl-deepracer'\n",
    "pretrainModelDesc = \"Default-\"\n",
    "\n",
    "# Duration of job in seconds (1 hours)\n",
    "job_duration_in_seconds = 3600 * 1\n",
    "\n",
    "if retrain == False: # Training a new model \n",
    "    # S3 bucket\n",
    "    s3_bucket = 'deepracer-trainingexercise-' + aws_region + '-' + accountID \n",
    "    s3_prefix = job_name = job_name_prefix + \"sagemaker-\" + timestamp\n",
    "    s3_prefix_robomaker = job_name_prefix + \"robomaker-\" + timestamp\n",
    "    \n",
    "    pretrained_s3_bucket = None\n",
    "    pretrained_s3_prefix = None\n",
    "\n",
    "if retrain == True: # Retraining an old model \n",
    "    \n",
    "    pretrained_s3_bucket = 'deepracer-trainingexercise-' + aws_region + '-' + accountID\n",
    "    pretrained_s3_prefix = 'retrainmodel/' # Don't need to include the 'model/' folder in the prefix\n",
    "    \n",
    "    job_name = job_name_prefix +'-'+ pretrainModelDesc + \"retrain-\" + timestamp\n",
    "    s3_bucket = 'deepracer-trainingexercise-' + aws_region + '-' + accountID\n",
    "    s3_prefix = job_name_prefix +'-'+ pretrainModelDesc + \"sagemaker-retrain-\" + timestamp\n",
    "    s3_prefix_robomaker = job_name_prefix +'-'+ pretrainModelDesc + \"robomaker-retrain-\" + timestamp\n",
    "    \n",
    "s3_output_path = 's3://{}/'.format(s3_bucket) # SDK appends the job name and output folder\n",
    "\n",
    "print('Model checkpoints and other metadata will be stored at: ' + s3_output_path + job_name)\n",
    "print(\"RoboMaker logging will be stored at : {}{}\".format(s3_output_path, s3_prefix_robomaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the VPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Amazon SageMaker and AWS RoboMaker have to communicate with each other over the network, they both need to run in VPC mode. The AWS CloudFormation template you launched built the networking layer that supports these services. However, this notebook needs to discover what VPC ID it is running in and the subnet where AWS Robomaker and Amazon SageMaker can create instances. To support these node-to-node communications, a security group will need to be attached. \n",
    "\n",
    "Running the code block below allows this notebook to discover these resource IDs and load them into memory.\n",
    "\n",
    "This notebook is programmed to look for a VPC with a IP block range of 10.96.0.0/16. If you changed the default AWS CloudFormation stack parameters at stack creation, this code block may fail to run. Make sure the IP block range matches the IP block range of 10.96.0.0/16. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.client('ec2')\n",
    "\n",
    "default_vpc = [vpc['VpcId'] for vpc in ec2.describe_vpcs()['Vpcs'] if vpc[\"CidrBlock\"] == '10.96.0.0/16'][0] \n",
    "\n",
    "default_security_groups = [group[\"GroupId\"] for group in ec2.describe_security_groups()['SecurityGroups'] \\\n",
    "                   if group[\"GroupName\"] == \"default\" and group[\"VpcId\"] == default_vpc]\n",
    "\n",
    "default_subnets = [subnet[\"SubnetId\"] for subnet in ec2.describe_subnets()[\"Subnets\"] \\\n",
    "                  if subnet[\"VpcId\"] == default_vpc and subnet['MapPublicIpOnLaunch']==False]\n",
    "\n",
    "print(\"Using VPC:\", default_vpc)\n",
    "print(\"Using security group:\", default_security_groups)\n",
    "print(\"Using subnets:\", default_subnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the configurations  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running these simulations via Amazon SageMaker, you gain greater control over the settings in the simulated environment and the data being collected. Let's discuss some of these files and the role they play in helping with model learning by rewarding good driving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The reward function\n",
    "\n",
    "The environment is defined in a Python file called “deepracer_env.py,” which can be found at `src/robomaker/environments/`. This file implements the gym interface for your Gazebo-based AWS RoboMaker simulator. This is a common environment file used by both Amazon SageMaker and AWS RoboMaker. The environment variable - `NODE_TYPE` defines which node the code is running on. So the expressions that have `rospy` dependencies are executed on AWS RoboMaker only.  \n",
    "\n",
    "You can experiment with different reward functions by modifying `reward_function` in this file. You can also change the action space and steering angles by modifying the step method in `DeepRacerDiscreteEnv` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize src/robomaker/environments/deepracer_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "One way to improve your model's performance is to enact a better or more effective training process. For example, to develop a robust model, training must provide your agent more or less evenly distributed sampling over the agent's action space. This requires a sufficient mix of explorations and exploitations. The variables that affect this include the amount of training data used (number of episodes between each training and batch size), how fast the agent can learn (learning rate), and the portion of exploration (entropy). To make training practical, you may want to experiment with speeding up the learning process. The variables that affect this include learning rate, batch size, number of epochs, and discount factor.\n",
    "\n",
    "The variables affecting the training process are known as *hyperparameters*. They're algorithm attributes that are not properties of the underlying model. Unfortunately, hyperparameters are empirical in nature. Their optimal values are not known *a priori* for all practical purposes and require systematic experimentation through iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize src/robomaker/presets/deepracer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training entry point\n",
    "\n",
    "The training code is written in the file `training_worker.py`, which is uploaded in the `/src` directory. This is the code that is being used to start a Redis server that will receive agent experiences by rollout training worker[s]. After receiving these agent experiences, `training_worker.py` will trigger model training after a defined number of episodes are received. After the training cycle has finished, it will upload the new model weights to the defined S3 bucket, and notify the workers to update their models and execute the next set of episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize src/training_worker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading configurations to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload `src/robomaker/presets/deepracer.py` and `src/robomaker/environments/deepracer_env.py` to `s3_bucket` `s3_prefix`. These files must be present when the Amazon SageMaker training job is created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_location = \"s3://%s/%s\" % (s3_bucket, s3_prefix)\n",
    "\n",
    "# Make any changes to the envrironment and preset files below and upload these files\n",
    "!aws s3 cp src/robomaker/environments/ {s3_location}/environments/ --recursive --exclude \".ipynb_checkpoints*\" --exclude \"*.pyc\"\n",
    "!aws s3 cp src/robomaker/presets/ {s3_location}/presets/ --recursive --exclude \".ipynb_checkpoints*\" --exclude \"*.pyc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLEstimator for training RL jobs\n",
    "\n",
    "To set up your training environment, you will call the class RLEstimator. This estimator executes an RLEstimator script in a managed RL execution environment within an Amazon SageMaker training job. The managed RL environment is an Amazon-built Docker container that executes functions defined in the supplied entry_point Python script.\n",
    "\n",
    "[RLEstimator Doc](https://sagemaker.readthedocs.io/en/stable/sagemaker.rl.html)\n",
    "\n",
    "When calling this class, we can define:\n",
    "1. Source directory, which has the environment file, preset and training code\n",
    "2. Entry point as the training code\n",
    "3. Specify the RL toolkit and framework used. This then will apply to the RL container\n",
    "4. Define the RLCOACH preset of `deepracer` \n",
    "5. Training parameters\n",
    "  - instance count - **Only 1 training instance is supported for now**\n",
    "  - instance type  - Default to ml.c4.2xlarge\n",
    "  - job name \n",
    "  - s3_bucket - Bucket to store training data\n",
    "  - s3_prefix - Prefix to store model checkpoint and metadata \n",
    "  - pretrained_s3_bucket - S3 Bucket where a prior model is saved. Only needed if retraining\n",
    "  - pretrained_s3_prefix - The path to where the file is saved. Only needed if retraining\n",
    "6.  Metrics that you want to capture from Amazon CloudWatch logs to monitor the training process. \n",
    "    \n",
    "Training is not started until you call the fit()\n",
    "    \n",
    "Below are algorithm-specific parameters which might change for different algorithms. In this example, we use [ClippedPPO](https://coach.nervanasys.com/algorithms/policy_optimization/cppo/index.html). This data could be sent to Amazon CloudWatch or Amazon SageMaker Notebooks for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    # Training> Name=main_level/agent, Worker=0, Episode=19, Total reward=-102.88, Steps=19019, Training iteration=1\n",
    "    {'Name': 'reward-training',\n",
    "     'Regex': '^Training>.*Total reward=(.*?),'},\n",
    "    \n",
    "    # Policy training> Surrogate loss=-0.32664725184440613, KL divergence=7.255815035023261e-06, Entropy=2.83156156539917, training epoch=0, learning_rate=0.00025\n",
    "    {'Name': 'ppo-surrogate-loss',\n",
    "     'Regex': '^Policy training>.*Surrogate loss=(.*?),'},\n",
    "     {'Name': 'ppo-entropy',\n",
    "     'Regex': '^Policy training>.*Entropy=(.*?),'},\n",
    "   \n",
    "    # Testing> Name=main_level/agent, Worker=0, Episode=19, Total reward=1359.12, Steps=20015, Training iteration=2\n",
    "    {'Name': 'reward-testing',\n",
    "     'Regex': '^Testing>.*Total reward=(.*?),'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RLCOACH_PRESET = \"deepracer\"\n",
    "instance_type = \"ml.c4.2xlarge\"\n",
    "\n",
    "print('S3 Logging Bucket: ' + s3_bucket)\n",
    "print('S3 Logging Prefix: ' + s3_prefix)\n",
    "\n",
    "#if retrain == True:\n",
    "print('Pretrained Model Bucket: ' + str(pretrained_s3_bucket))\n",
    "print('Pretrained Model Prefix: ' + str(pretrained_s3_bucket))\n",
    "estimator = RLEstimator(entry_point=\"training_worker.py\",\n",
    "                        source_dir='src',\n",
    "                        dependencies=[\"common/sagemaker_rl\"],\n",
    "                        toolkit=RLToolkit.COACH,\n",
    "                        toolkit_version='0.11',\n",
    "                        framework=RLFramework.TENSORFLOW,\n",
    "                        role=role,\n",
    "                        train_instance_type=instance_type,\n",
    "                        train_instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        base_job_name=job_name_prefix,\n",
    "                        train_max_run=job_duration_in_seconds, # Maximum runtime in seconds\n",
    "                        hyperparameters={\"pretrained_s3_bucket\": pretrained_s3_bucket,\n",
    "                                         \"pretrained_s3_prefix\": pretrained_s3_prefix,\n",
    "                                         \"s3_bucket\": s3_bucket,\n",
    "                                         \"s3_prefix\": s3_prefix,\n",
    "                                         \"aws_region\": aws_region, \n",
    "                                         \"RLCOACH_PRESET\": RLCOACH_PRESET,\n",
    "                                      },\n",
    "                        metric_definitions = metric_definitions,\n",
    "                        subnets=default_subnets, # Required for VPC mode\n",
    "                        security_group_ids=default_security_groups, # Required for VPC mode\n",
    "                    )\n",
    "estimator.fit(job_name=job_name, wait=False, logs=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up AWS Robomaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the simulation environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, AWS RoboMaker will need a package containing the simulation environment. Below, you will download a package created by the AWS RoboMaker product team. \n",
    "\n",
    "This file is big, and it is not going to change frequently. So rather than downloading it each time you train a model, just check if that file is there. If you want to update this file, you can simply rename it or delete it from your S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulation_application_bundle_location = \"https://s3.amazonaws.com/deepracer-managed-resources/deepracer-github-simapp.tar.gz\"\n",
    "\n",
    "\n",
    "bundle_s3_key = 'deepracer/simulation_ws.tar.gz'\n",
    "\n",
    "result = s3.list_objects(Bucket=s3_bucket,Prefix=bundle_s3_key)\n",
    "if 'Contents' not in result:\n",
    "    print('Deepracer application simulation bundle not found... Downloading it now')\n",
    "    !wget {simulation_application_bundle_location}\n",
    "    print('Uploading simulation bundle to S3.')\n",
    "    !aws s3 cp deepracer-github-simapp.tar.gz s3://{s3_bucket}/{bundle_s3_key}\n",
    "else:\n",
    "    print('Deepracer application simulation bundle found at:')\n",
    "    print('s3://'+s3_bucket+'/'+bundle_s3_key)\n",
    "    print('Delete or rename this file in s3 to download a new source from deepracer team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload this to AWS RoboMaker as a simulation application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = \"deepracerSagemakerSimulation-\" + timestamp\n",
    "\n",
    "bundle_s3_key = 'deepracer/simulation_ws.tar.gz'\n",
    "bundle_source = {'s3Bucket': s3_bucket,\n",
    "                 's3Key': bundle_s3_key,\n",
    "                 'architecture': \"X86_64\"}\n",
    "simulation_software_suite={'name': 'Gazebo',\n",
    "                           'version': '7'}\n",
    "robot_software_suite={'name': 'ROS',\n",
    "                      'version': 'Kinetic'}\n",
    "rendering_engine={'name': 'OGRE', 'version': '1.x'}\n",
    "\n",
    "try:\n",
    "    response = robomaker.create_simulation_application(name=app_name,\n",
    "                                                   sources=[bundle_source],\n",
    "                                                   simulationSoftwareSuite=simulation_software_suite,\n",
    "                                                   robotSoftwareSuite=robot_software_suite,\n",
    "                                                   renderingEngine=rendering_engine\n",
    "                                                  )\n",
    "    simulation_app_arn = response[\"arn\"]\n",
    "    print(\"Created a new simulation app with ARN:\", simulation_app_arn)\n",
    "except Exception as e:\n",
    "    if \"AccessDeniedException\" in str(e):\n",
    "        display(Markdown(generate_help_for_robomaker_all_permissions(role)))\n",
    "        raise e\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the simulation job on AWS RoboMaker\n",
    "\n",
    "Before launching the simulation job on AWS RoboMaker, first make sure that all your defined parameters are correct for your testing scenario. This simulation can take several minutes to load, and it's billed by the hour--so make sure everything is correct before you begin.\n",
    "\n",
    "`World_NAME` is name of the world or track that you will load into AWS RoboMaker. \n",
    "\n",
    "1. `\"easy_track\"` - Drag race, long straight roadway with a center line down the middle \n",
    "2. `\"medium_track\"` - A big O, with four left turns to make a big loop\n",
    "3. `\"hard_track\"` - A more complex track that has two long straightaways, as well as a double left turn and a single right turn\n",
    "\n",
    "Create [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) simulation jobs to simulate the environment and share this data with Amazon SageMaker for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use more rollout workers for faster convergence\n",
    "num_simulation_workers = 1\n",
    "sim_failure_behavior = \"Continue\"\n",
    "\n",
    "envriron_vars = {\n",
    "                 \"MODEL_S3_BUCKET\": s3_bucket,\n",
    "                 \"MODEL_S3_PREFIX\": s3_prefix,\n",
    "                 \"ROS_AWS_REGION\": aws_region,\n",
    "                 \"WORLD_NAME\": \"hard_track\",  # Can be one of \"easy_track\", \"medium_track\", \"hard_track\"\n",
    "                 \"MARKOV_PRESET_FILE\": \"%s.py\" % RLCOACH_PRESET,\n",
    "                 \"NUMBER_OF_ROLLOUT_WORKERS\": str(num_simulation_workers)}\n",
    "\n",
    "\n",
    "simulation_application = {\"application\": simulation_app_arn,\n",
    "                          \"launchConfig\": {\"packageName\": \"deepracer_simulation\",\n",
    "                                           \"launchFile\": \"distributed_training.launch\",\n",
    "                                           \"environmentVariables\": envriron_vars}\n",
    "                         }\n",
    "                            \n",
    "vpcConfig = {\"subnets\": default_subnets,\n",
    "             \"securityGroups\": default_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "print('Simulation Environment Variables:')\n",
    "print('Model S3 Bucket: '+envriron_vars['MODEL_S3_BUCKET'])\n",
    "print('Model S3 Prefix: '+envriron_vars['MODEL_S3_PREFIX'])\n",
    "print('AWS Region: '+envriron_vars['ROS_AWS_REGION'])\n",
    "print('Track Name: '+envriron_vars['WORLD_NAME'])\n",
    "print('MARKOV Presets: '+envriron_vars['MARKOV_PRESET_FILE'])\n",
    "print('Number of Worker: '+envriron_vars['NUMBER_OF_ROLLOUT_WORKERS'])\n",
    "print()\n",
    "print('Simulation Application Files:')\n",
    "print('SimApp ARN: '+simulation_application['application'])\n",
    "print('SimApp Package Name: '+simulation_application['launchConfig']['packageName'])\n",
    "print('SimApp Launch File: '+simulation_application['launchConfig']['launchFile'])\n",
    "print()\n",
    "print('Networking Settings:')\n",
    "print('Subnet: ' + vpcConfig['subnets'][0])\n",
    "print('Subnet: ' + vpcConfig['subnets'][1])\n",
    "print('Subnet: ' + vpcConfig['subnets'][2])\n",
    "print('Subnet: ' + vpcConfig['subnets'][3])\n",
    "print('Security Groups: '+vpcConfig['securityGroups'][0])\n",
    "print('Public IP: '+str(vpcConfig['assignPublicIp']))\n",
    "print()\n",
    "print('Robomaker Create Simulation Parameters:')\n",
    "print('Robomaker Role ARN: '+role)\n",
    "print('Simulation Job Duration (Seconds): '+str(job_duration_in_seconds))\n",
    "print('Simulation Fail Behavior: '+sim_failure_behavior)\n",
    "print('Output Bucket: '+s3_bucket)\n",
    "print('Output Prefix: '+s3_prefix_robomaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is correct, run the code block below to start the simulator. If everything was done correctly, you should see the simulated track in AWS RoboMaker with your car navigating that track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for job_no in range(num_simulation_workers):\n",
    "    response =  robomaker.create_simulation_job(iamRole=role,\n",
    "                                            clientRequestToken=strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "                                            maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                            failureBehavior=sim_failure_behavior,\n",
    "                                            simulationApplications=[simulation_application],\n",
    "                                            vpcConfig=vpcConfig,\n",
    "                                            outputLocation={\"s3Bucket\":s3_bucket, \"s3Prefix\":s3_prefix_robomaker}\n",
    "                                            )\n",
    "    responses.append(response)\n",
    "\n",
    "print(\"Created the following jobs:\")\n",
    "job_arns = [response[\"arn\"] for response in responses]\n",
    "for job_arn in job_arns:\n",
    "    print(\"Job ARN\", job_arn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing simulations in AWS RoboMaker\n",
    "\n",
    "Your simulation will load in 10-15 minutes. After it loads, click the URL below to open the AWS RoboMaker service page for the simulation you just launched. There, you can open Gazebo to see your car running in the simulated environment.  \n",
    "\n",
    "Troubleshooting\n",
    "\n",
    "1. If your reward function is not valid Python syntax or causes an error when you run it, you could end up crashing the simulation. If Gazebo fails to load the simulation, this could be one of the causes.\n",
    "\n",
    "\n",
    "2. If your car is just sitting in the corner (x=0,y=0) and not moving, and you are attempting to retrain an old model, your old model may not have been loaded correctly. Check that the correct model files were uploaded to the right location as defined in 'pretrain_s3_bucket' and 'pretrain_s3_prefix'\n",
    "\n",
    "    The training algorithm has two phases. The first is when the RL model is used to make the car move in the track, while the second is when the algorithm uses the information gathered in the first phase to improve the model. In the second phase, no new commands are sent to the car, meaning it will appear as if it is stopped, spinning in circles, or drifting off aimlessly.\n",
    "\n",
    "\n",
    "3. It is possible to move elements of the simulated track in AWS RoboMaker Gazebo. Doing so will affect how the model is seeing and could adversely affect model training. When navigating around this window, be careful not to move objects, or you may have to restart training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(generate_robomaker_links(job_arns, aws_region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics for training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your model is being trained, it will send several metrics to Amazon CloudWatch as both metrics and logs. One of these is the number of rewards that your model earned per episode. This data is appended to a file in your S3 bucket over the course of the training. The first cell builds the plot to display this data, and the second code cell is downloading the latest data set from training and graphing it to help you see if your model is training and how effectively.\n",
    "\n",
    "You can simply re-run the second code block to update this graph over the course of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = \"/tmp/{}\".format(job_name)\n",
    "os.system(\"mkdir {}\".format(tmp_dir))\n",
    "print(\"Create local folder {}\".format(tmp_dir))\n",
    "intermediate_folder_key = \"{}/output/intermediate\".format(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_name = \"worker_0.simple_rl_graph.main_level.main_level.agent_0.csv\"\n",
    "key = intermediate_folder_key + \"/\" + csv_file_name\n",
    "wait_for_s3_object(s3_bucket, key, tmp_dir)\n",
    "\n",
    "csv_file = \"{}/{}\".format(tmp_dir, csv_file_name)\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df.dropna(subset=['Training Reward'])\n",
    "x_axis = 'Episode #'\n",
    "y_axis = 'Training Reward'\n",
    "\n",
    "plt = df.plot(x=x_axis,y=y_axis, figsize=(12,5), legend=True, style='b-')\n",
    "plt.set_ylabel(y_axis);\n",
    "plt.set_xlabel(x_axis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up training resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following two code blocks will clean up the Amazon SageMaker training instance and the AWS RoboMaker simulation job. This should happen automatically if your training finished successfully, but if you want to terminate a training that's still running, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_arn in job_arns:\n",
    "    robomaker.cancel_simulation_job(job=job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_session.sagemaker_client.stop_training_job(TrainingJobName=estimator._current_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, a model has been trained and saved to the bucket defined in `s3_bucket` to a path of `s3_prefix`. Inside this folder in Amazon S3, you will find a few directories:\n",
    "\n",
    "1. `environments` - Location of `deepracer_env.py` used in this simulation\n",
    "2. `ip` - Status and IP address from simulator \n",
    "3. `model` - Model checkpoint files (you'll need these when retraining a model you've trained previously) \n",
    "4. `output` - A finished, packaged, and optimized model, which you could load on your AWS DeepRacer car \n",
    "5. `output/intermediate` - The CSV file of number of training rewards over the number of training episodes\n",
    "5. `presets` - Location of `deepracer.py` used in this simulation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation jobs are deployed like training jobs. However, you do not need to deploy an Amazon SageMaker training instance to apply new learning to the working model. The point of an evaluation is to help you assess the model's behaviors in a controlled simulation.\n",
    "\n",
    "Our evaluation is based on the number of successful laps around the track the car makes. `NUMBER_OF_TRIALS` is currently set to `20`, and will be running on `hard_track`. The length of time the car has to complete these `20` laps would be defined by `job_duration_in_seconds`. This value was defined for your training job, but if you'd like to decrease it, you can uncomment it below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envriron_vars = {\"MODEL_S3_BUCKET\": s3_bucket,\n",
    "                 \"MODEL_S3_PREFIX\": s3_prefix,\n",
    "                 \"ROS_AWS_REGION\": aws_region,\n",
    "                 \"NUMBER_OF_TRIALS\": str(20),\n",
    "                 \"MARKOV_PRESET_FILE\": \"%s.py\" % RLCOACH_PRESET,\n",
    "                 \"WORLD_NAME\": \"hard_track\",\n",
    "                 }\n",
    "\n",
    "# Duration of evaluation job in seconds (1 hours)\n",
    "#job_duration_in_seconds = 3600 * 1 \n",
    "\n",
    "simulation_application = {\"application\":simulation_app_arn,\n",
    "                          \"launchConfig\": {\"packageName\": \"deepracer_simulation\",\n",
    "                                           \"launchFile\": \"evaluation.launch\",\n",
    "                                           \"environmentVariables\": envriron_vars}\n",
    "                         }\n",
    "                            \n",
    "vpcConfig = {\"subnets\": default_subnets,\n",
    "             \"securityGroups\": default_security_groups,\n",
    "             \"assignPublicIp\": True}\n",
    "\n",
    "response =  robomaker.create_simulation_job(iamRole=role,\n",
    "                                        clientRequestToken=strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()),\n",
    "                                        maxJobDurationInSeconds=job_duration_in_seconds,\n",
    "                                        failureBehavior=\"Continue\",\n",
    "                                        simulationApplications=[simulation_application],\n",
    "                                        vpcConfig=vpcConfig,\n",
    "                                        outputLocation={\"s3Bucket\":s3_bucket, \"s3Prefix\":s3_prefix_robomaker}\n",
    "                                        )\n",
    "print(\"Created the following job:\")\n",
    "print(\"Job ARN\", response[\"arn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up simulation application resource\n",
    "\n",
    "Your evaluation job may fail if your car cannot complete the defined number of successful trials. This could indicate that you need to do more training.\n",
    "\n",
    "You can point this notebook to the model training checkpoint files, and refine your mode better as you get more familiar with these configurations and how the model performs under different conditions.\n",
    "\n",
    "To clear the outputs of these code blocks, click **Kernel** on the Jupyter file bar and then select **Restart and Clear Output**'. This will reset all the variables defined during this run and clear the outputs, letting you start fresh again.\n",
    "\n",
    "Running the code block below will ensure that the AWS RoboMaker evaluation simulation app has been shut down.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robomaker.delete_simulation_application(application=simulation_app_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to be walking away from this exercise for a while, consider stopping this Amazon SageMaker instance. It's running on an ml.t3.xlarge. The AWS CloudFormation stack can be left, as the networking is part of the AWS free tier. Amazon S3 will bill on a price per GB per month for the data that is saved in `s3_bucket`. When you want to come back to this exercise, simply start this Amazon SageMaker instance and launch this Jupyter notebook again.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Congratulations! You now have successfully:\n",
    "1. Configured the appropriate environment and installed the right packages to utilize Amazon SageMaker\n",
    "2. Used Amazon SageMaker to build, train, and evaluate a reinforcement learning model for AWS DeepRacer\n",
    "3. Created, launched, and visualized a simulated environment in AWS RoboMaker|"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
